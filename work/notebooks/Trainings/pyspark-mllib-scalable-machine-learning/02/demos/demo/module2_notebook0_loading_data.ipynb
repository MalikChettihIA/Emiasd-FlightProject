{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24d2ba9d-2477-47b7-9c3e-edc337d1eda2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Module 2 Notebook 0: Loading the Data\n",
    "\n",
    "In this notebook, we'll focus specifically loading the data from the parquet files in storage, verifying the contents and storing it as Spark tables so that we can easily refer to it on all the future notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4694bb75-0869-4a46-9b9f-75c8fca4db8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Setup\n",
    "\n",
    "To get set up, do these tasks first: \n",
    "\n",
    "- Upload the ecommerce-* files to storage accessible to your Spark cluster\n",
    "- Regardless of how you get the files into your storage, you will have to replace the paths I use in the code below with the paths that make sense for your environment as well as the right authentication method. The ones I use are for accessing storage in the Databricks workspace that I have access to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad3def8e-498f-4e8a-a66a-7fc6a31f3495",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- First, define the paths of the files we are reading.\n",
    "- Replace with what is appropriate with your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ca58666-9ed3-4db5-a2f9-252fbe0c7786",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define paths for each file in the Workspace storage\n",
    "customers_path = \"data/ecommerce_customers.parquet\"\n",
    "products_path = \"data/ecommerce_products.parquet\"\n",
    "interactions_path = \"data/ecommerce_interactions.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ff0cd29-4a85-425b-9adc-5586f821557a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's load and verify the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Cr√©er une SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MonApplication\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d98a573-7081-4a1e-8406-c9e80b827bd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+------+-------+-----------+----------------+\n",
      "|customer_id|age|gender|country|tenure_days|membership_level|\n",
      "+-----------+---+------+-------+-----------+----------------+\n",
      "|          1| 40|     M|     US|        936|        Platinum|\n",
      "|          2| 33|     M|     UK|        192|          Silver|\n",
      "|          3| 42|     M|     MX|        160|          Bronze|\n",
      "|          4| 53|     M|     AU|        823|          Bronze|\n",
      "|          5| 32|     F|     US|        513|          Bronze|\n",
      "+-----------+---+------+-------+-----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+--------+-----+----------+\n",
      "|product_id|category|price|avg_rating|\n",
      "+----------+--------+-----+----------+\n",
      "|         1|Clothing|33.64|       3.8|\n",
      "|         2|Clothing|24.05|       3.5|\n",
      "|         3|  Beauty|58.67|       4.1|\n",
      "|         4|Clothing|11.15|       4.3|\n",
      "|         5|  Beauty|47.74|       4.5|\n",
      "+----------+--------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------+----------+--------------------+----------------+------------------+---------------+-----------+-------+---------------+\n",
      "|customer_id|product_id|           timestamp|interaction_type|time_spent_seconds|purchase_amount|user_rating| device|previous_visits|\n",
      "+-----------+----------+--------------------+----------------+------------------+---------------+-----------+-------+---------------+\n",
      "|       5390|       635|2024-04-11 11:40:...|            view|                21|            0.0|        0.0| mobile|              4|\n",
      "|       5390|       635|2024-04-11 11:45:...|     add_to_cart|                25|            0.0|        0.0| mobile|              4|\n",
      "|       5390|       635|2024-04-11 11:48:...|        purchase|                51|          78.69|        0.0| mobile|              4|\n",
      "|       8426|       195|2024-04-11 11:52:...|            view|                 5|            0.0|        0.0| mobile|              1|\n",
      "|       4951|       698|2024-04-11 11:56:...|            view|                15|            0.0|        0.0|desktop|              3|\n",
      "+-----------+----------+--------------------+----------------+------------------+---------------+-----------+-------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the parquet files\n",
    "customers_df = spark.read.parquet(customers_path)\n",
    "products_df = spark.read.parquet(products_path)\n",
    "interactions_df = spark.read.parquet(interactions_path)\n",
    "\n",
    "customers_df.show(5)\n",
    "products_df.show(5)\n",
    "interactions_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cab4ee7-894b-45fd-9295-f5670d1f81e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's review the count and the distribution of interaction types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d70ba999-b40a-4c0e-84b4-3cd9b87a4f88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers count: 10000\n",
      "Products count: 1000\n",
      "Interactions count: 112942\n"
     ]
    }
   ],
   "source": [
    "print(\"Customers count:\", customers_df.count())\n",
    "print(\"Products count:\", products_df.count())\n",
    "print(\"Interactions count:\", interactions_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a515f553-49d0-4d6e-9fe7-8902b225a428",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[interaction_type: string, count: bigint, percentage: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, round\n",
    "\n",
    "# Calculate distribution of interaction_type in record count\n",
    "interaction_count_df = interactions_df.groupBy(\"interaction_type\").agg(count(\"*\").alias(\"count\"))\n",
    "\n",
    "# Calculate total interactions for percentage calculation\n",
    "total_interactions = interactions_df.count()\n",
    "\n",
    "# Calculate percentage distribution\n",
    "interaction_percentage_df = interaction_count_df.withColumn(\"percentage\", round((col(\"count\") / total_interactions) * 100, 2))\n",
    "\n",
    "# Display the distribution\n",
    "display(interaction_percentage_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13982fe1-8a3c-408f-9e0b-b162afd7fcba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We'll load our e-commerce dataset from parquet files and create persistent tables for use across all modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33af0b10-0b7c-437c-9938-9df76a3de7e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created persistent tables in 'ecommerce' database\n"
     ]
    }
   ],
   "source": [
    "# Create database if it doesn't exist\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS ecommerce\")\n",
    "spark.sql(\"USE ecommerce\")\n",
    "\n",
    "# Drop tables if they exist\n",
    "spark.sql(\"DROP TABLE IF EXISTS ecommerce.interactions\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS ecommerce.customers\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS ecommerce.products\")\n",
    "\n",
    "# Create or replace persistent tables\n",
    "interactions_df.write.mode(\"overwrite\").saveAsTable(\"ecommerce.interactions\")\n",
    "customers_df.write.mode(\"overwrite\").saveAsTable(\"ecommerce.customers\")\n",
    "products_df.write.mode(\"overwrite\").saveAsTable(\"ecommerce.products\")\n",
    "\n",
    "print(\"Created persistent tables in 'ecommerce' database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f260a5b-7a6d-4bcf-b21d-150519aa1187",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now continue on Module 2 Notebook 1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = spark.table(\"ecommerce.interactions\")\n",
    "customers_df = spark.table(\"ecommerce.customers\")\n",
    "products_df = spark.table(\"ecommerce.products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adc01d52-1c02-424b-88b3-83766307be07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3646665849.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    DROP DATABASE ecommerce CASCADE\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%sql\n",
    "DROP DATABASE ecommerce CASCADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6650313671844208,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "module2_notebook0_loading_data",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
