{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbb7895c-3760-43e7-b46a-b50e94fd326e",
   "metadata": {},
   "source": [
    "# Jointure NAN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dc94df3-96e9-4bd1-bad7-c9b20540c774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from file:///home/jovyan/work/apps/Emiasd-Flight-Data-Analysis.jar\n",
      "Finished download of Emiasd-Flight-Data-Analysis.jar\n",
      "Using cached version of Emiasd-Flight-Data-Analysis.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar file:///home/jovyan/work/apps/Emiasd-Flight-Data-Analysis.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e43a5208-f1eb-47fa-bb14-fc1031dc5376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "args = Array(jupyter)\n",
       "spark = org.apache.spark.sql.SparkSession@6a356ab0\n",
       "session = org.apache.spark.sql.SparkSession@6a356ab0\n",
       "configuration = AppConfiguration(local,CommonConfig(42,DataConfig(/home/jovyan/work/data,FileConfig(/home/jovyan/work/data/FLIGHT-3Y/Flights/*.csv),FileConfig(/home/jovyan/work/data/FLIGHT-3Y/Weather/*.txt),FileConfig(/home/jovyan/work/data/FLIGHT-3Y/wban_airport_timezone.csv)),OutputConfig(/home/jovyan/work/output,FileConfig(/home/jovyan/work/output/data),File...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "AppConfiguration(local,CommonConfig(42,DataConfig(/home/jovyan/work/data,FileConfig(/home/jovyan/work/data/FLIGHT-3Y/Flights/*.csv),FileConfig(/home/jovyan/work/data/FLIGHT-3Y/Weather/*.txt),FileConfig(/home/jovyan/work/data/FLIGHT-3Y/wban_airport_timezone.csv)),OutputConfig(/home/jovyan/work/output,FileConfig(/home/jovyan/work/output/data),File..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import com.flightdelay.config.{AppConfiguration, ConfigurationLoader, ExperimentConfig}\n",
    "import com.flightdelay.data.loaders.FlightDataLoader\n",
    "\n",
    "//Env Configuration\n",
    "val args: Array[String] = Array(\"jupyter\")\n",
    "\n",
    "val spark = SparkSession.builder()\n",
    "  .config(sc.getConf)\n",
    "  .getOrCreate()\n",
    "\n",
    "// Rendre la session Spark implicite\n",
    "implicit val session = spark\n",
    "implicit val configuration: AppConfiguration = ConfigurationLoader.loadConfiguration(args)\n",
    "implicit val experiment: ExperimentConfig = configuration.experiments(1)\n",
    "\n",
    "//Set CheckPoint Dir\n",
    "spark.sparkContext.setCheckpointDir(s\"${configuration.common.output.basePath}/spark-checkpoints\")\n",
    "// Réduire les logs pour plus de clarté\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9270b596-adb2-42d6-84cf-ae9072b1592f",
   "metadata": {},
   "source": [
    "## Flights Raw - Process Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11238005-cf4c-4a8a-8743-6dcbcf36e705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rawFlightsDFPath = /home/jovyan/work/output/common/data/raw_flights.parquet\n",
       "rawFlightsDF = [FL_DATE: date, OP_CARRIER_AIRLINE_ID: int ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[FL_DATE: date, OP_CARRIER_AIRLINE_ID: int ... 10 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rawFlightsDFPath = s\"${configuration.common.output.basePath}/common/data/raw_flights.parquet\"\n",
    "val rawFlightsDF = spark.read.parquet(rawFlightsDFPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a32c375f-62e7-44a1-9104-7296ef22e854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: date (nullable = true)\n",
      " |-- OP_CARRIER_AIRLINE_ID: integer (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n",
      " |-- ORIGIN_AIRPORT_ID: integer (nullable = true)\n",
      " |-- DEST_AIRPORT_ID: integer (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- ARR_DELAY_NEW: double (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
      " |-- WEATHER_DELAY: double (nullable = true)\n",
      " |-- NAS_DELAY: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawFlightsDF.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57afcaba-01d3-442b-b6ea-2aee5c106f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[Preprocessing] Flight Data Preprocessing Pipeline - Start\n",
      "================================================================================\n",
      "\n",
      "Loading raw data from parquet:\n",
      "  - Path: /home/jovyan/work/output/common/data/raw_flights.parquet\n",
      "  - Loaded 486133 raw records\n",
      "\n",
      "[Pipeline Step 1/9] Cleaning flight data...\n",
      "\n",
      "================================================================================\n",
      "[STEP 2][DataCleaner] Flight Data Cleaning - Start\n",
      "================================================================================\n",
      "\n",
      "Original dataset: 486133 records\n",
      "\n",
      "Phase 1: Basic Cleaning\n",
      "  - Current count: 486133 records\n",
      "\n",
      "Phase 2: Filter Invalid Flights\n",
      "  - Filtering cancelled and diverted flights\n",
      "  - Filtering invalid departure times\n",
      "  - Filtering invalid airports\n",
      "  - Current count: 486133 records\n",
      "\n",
      "Phase 3: Data Type Conversion\n",
      "Conversion des types de données: NAS_DELAY, OP_CARRIER_AIRLINE_ID, OP_CARRIER_FL_NUM, WEATHER_DELAY, DEST_AIRPORT_ID, ORIGIN_AIRPORT_ID, CRS_ELAPSED_TIME, FL_DATE, CRS_DEP_TIME, ARR_DELAY_NEW\n",
      "  - Filtering invalid flight dates\n",
      "  - Current count: 486133 records\n",
      "\n",
      "Phase 5: Final Validation\n",
      "  - Validation passed: 486133 records\n",
      "\n",
      "==================================================\n",
      "Cleaning Summary\n",
      "==================================================\n",
      "Original records:       486,133\n",
      "Final records:          486,133\n",
      "Removed records:              0\n",
      "Reduction:             0%\n",
      "==================================================\n",
      "[Pipeline Step 2/9] Enriching with Datasets ...\n",
      "[FlightDataSetFilterGenerator] Total vols: 486133\n",
      " - D1     :    18443 vols (3.79%)\n",
      " - D3     :    42568 vols (8.76%)\n",
      " - D4     :   149036 vols (30.66%)\n",
      " - D2_15  :     1076 vols (0.22%)\n",
      " - D2_30  :      592 vols (0.12%)\n",
      " - D2_45  :      347 vols (0.07%)\n",
      " - D2_60  :      200 vols (0.04%)\n",
      " - D2_90  :       89 vols (0.02%)\n",
      "[Pipeline Step 2/9] Enriching with WBAN...\n",
      "\n",
      "================================================================================\n",
      "[Preprocessing] Flight WBAN Enrichment - Start\n",
      "================================================================================\n",
      "\n",
      "Loading WBAN-Airport-Timezone mapping:\n",
      "  - Parquet path: /home/jovyan/work/output/common/data/raw_wban_airport_timezone.parquet\n",
      "  ✓ Loading from existing Parquet\n",
      "  - Loaded 305 airport-WBAN mappings\n",
      "\n",
      "  - Added UTC_CRS_DEP_TIME and UTC_FL_DATE conversion\n",
      "  - Handling timezone offsets and date boundaries\n",
      "\n",
      "Enrichment statistics:\n",
      "  - Total flights: 461369\n",
      "  - Flights with origin WBAN: 461369 (100%)\n",
      "  - Flights with destination WBAN: 461369 (100%)\n",
      "\n",
      "================================================================================\n",
      "[Preprocessing] Flight WBAN Enrichment - End\n",
      "================================================================================\n",
      "[Pipeline Step 3/9] Generating arrival data...\n",
      "\n",
      "================================================================================\n",
      "[Preprocessing] Flight Arrival Data Generation - Start\n",
      "================================================================================\n",
      "\n",
      "Step 1: Computing UTC arrival time and date\n",
      "Step 2: Computing local arrival time and date (destination timezone)\n",
      "Step 3: Generating derived features\n",
      "\n",
      "Arrival Data Statistics:\n",
      "  - Total flights: 461369\n",
      "  - Crosses midnight (local): 18066 (4%)\n",
      "  - Crosses midnight (UTC): 75728 (16%)\n",
      "  - Flies eastward: 113119 (25%)\n",
      "  - Flies westward: 113023 (24%)\n",
      "\n",
      "================================================================================\n",
      "[Preprocessing] Flight Arrival Data Generation - End\n",
      "================================================================================\n",
      "[Pipeline Step 4/9] Generating flight features...\n",
      "\n",
      "================================================================================\n",
      "[STEP 2][FlightDataGenerator] Flight Data Generator - Start ...\n",
      "================================================================================\n",
      "Original Column Counts: 39\n",
      "\n",
      "Phase 1: Add Temporal Features\n",
      "Temporal features added: 30\n",
      "\n",
      "Phase 2: Add Flight Characteristics\n",
      "Added Flight features: 7\n",
      "\n",
      "Phase 3: Add Period <indicator\n",
      "Added Flight features: 16\n",
      "\n",
      "Phase 4: Add Geographical Features\n",
      "Added Flight features: 8\n",
      "\n",
      "Phase 5 : Add Aggregated Features\n",
      "Added Flight features: 5\n",
      "\n",
      "=== Enrichment Summary ===\n",
      "\n",
      "Original Columns: 39\n",
      "Columns after enrichment: 103\n",
      "Enriched Columns: 64\n",
      "Dataset size: 461369\n",
      "\n",
      "[Pipeline Step 5/9] Creating previous late flight features...\n",
      "\n",
      "[PreviousLateFlightFeature] Creating PREV_AIRCRAFT_ARR_DELAY and turnaround_buffer features...\n",
      "  - Repartitioning by AIRCRAFT_ID and FL_DATE...\n",
      "  - Processing 461,369 flights\n",
      "  - Applying window function to compute previous flight features...\n",
      "  - Computing turnaround_buffer...\n",
      "  ✓ PREV_AIRCRAFT_ARR_DELAY and turnaround_buffer features created successfully\n",
      "[Pipeline Step 5.5/9] Checkpointing after feature generation...\n",
      "\n",
      "  [After feature generation] Memory: 2.00 GB / 3.00 GB (0%)\n",
      "[Pipeline Step 6/9] Generating labels...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "[STEP 2][FlightLabelGenerator] Flight Label Generator - Start ...\n",
      "================================================================================\n",
      "\n",
      "Phase 1: Validate Required Columns\n",
      "- Validation of required columns: OK\n",
      "\n",
      "Phase 2: Handling missing values for delays\n",
      "\n",
      "Phase 2: Adding basic labels for different thresholds\n",
      "[Pipeline Step 6.5/9] Checkpointing after label generation...\n",
      "\n",
      "  [After label generation] Memory: 1.00 GB / 3.00 GB (0%)\n",
      "[Pipeline Step 7/9] Calculating avg delay features...\n",
      "\n",
      "================================================================================\n",
      "[AvgDelayFeatureGenerator] Flight Average Delay Generator - Start\n",
      "================================================================================\n",
      "\n",
      "[Before processing] Memory:\n",
      "  Used: 434 MB / 3,072 MB (14%)\n",
      "\n",
      "[Step 1] Preparing timestamps...\n",
      "  ✓ Checkpointing intermediate data...\n",
      "  ✓ Processing 461369 flights\n",
      "\n",
      "[After checkpoint] Memory:\n",
      "  Used: 398 MB / 3,072 MB (12%)\n",
      "\n",
      "[Step 2] Creating window specification...\n",
      "\n",
      "[Step 3] Computing all statistics in single pass...\n",
      "  ✓ Generated 5 proportion features + 5 base statistics\n",
      "\n",
      "[Step 4] Filling null values...\n",
      "\n",
      "[Step 5] Checkpointing final result...\n",
      "\n",
      "[After completion] Memory:\n",
      "  Used: 1,149 MB / 3,072 MB (37%)\n",
      "\n",
      "[AvgDelayFeatureGenerator] Completed successfully\n",
      "================================================================================\n",
      "[Pipeline Step 7.5/9] Checkpointing after avg delay...\n",
      "\n",
      "  [After avg delay] Memory: 2.00 GB / 3.00 GB (0%)\n",
      "[Pipeline Step 9/9] Validating schema...\n",
      "\n",
      "================================================================================\n",
      "Schema Validation\n",
      "================================================================================\n",
      "\n",
      "Validating base columns:\n",
      "  ✓ OP_CARRIER_AIRLINE_ID (IntegerType)\n",
      "  ✓ OP_CARRIER_FL_NUM (IntegerType)\n",
      "  ✓ DEST_AIRPORT_ID (IntegerType)\n",
      "  ✓ ORIGIN_AIRPORT_ID (IntegerType)\n",
      "  ✓ CRS_ELAPSED_TIME (DoubleType)\n",
      "  ✓ CRS_DEP_TIME (IntegerType)\n",
      "  ✓ UTC_FL_DATE (DateType)\n",
      "\n",
      "Validating generated columns:\n",
      "  ✓ feature_departure_hour\n",
      "  ✓ feature_flight_month\n",
      "  ✓ feature_flight_year\n",
      "  ✓ feature_flight_quarter\n",
      "  ✓ feature_flight_day_of_week\n",
      "  ✓ feature_is_weekend\n",
      "  ✓ feature_route_id\n",
      "  ✓ feature_distance_category\n",
      "  ✓ ORIGIN_WBAN\n",
      "  ✓ ORIGIN_TIMEZONE\n",
      "  ✓ DEST_WBAN\n",
      "  ✓ DEST_TIMEZONE\n",
      "\n",
      "Validating label columns:\n",
      "  ✓ label_arr_delay_filled\n",
      "  ✓ label_weather_delay_filled\n",
      "  ✓ label_nas_delay_filled\n",
      "  ✓ label_is_delayed_15min\n",
      "  ✓ label_is_delayed_30min\n",
      "  ✓ label_is_delayed_60min\n",
      "  ✓ label_is_delayed_90min\n",
      "\n",
      "================================================================================\n",
      "✓ Schema Validation PASSED - 137 columns validated\n",
      "================================================================================\n",
      "\n",
      "Saving preprocessed flight data to parquet:\n",
      "  - Path: /home/jovyan/work/output/common/data/processed_flights.parquet\n",
      "  - Using optimized write strategy\n",
      "\n",
      "  [Before write] Memory: 2.00 GB / 3.00 GB (0%)\n",
      "  - Rows to write: 461369\n",
      "\n",
      "  [Step 1/3] Final checkpoint before write...\n",
      "  ✓ Checkpoint completed\n",
      "\n",
      "  [After checkpoint] Memory: 1.00 GB / 3.00 GB (0%)\n",
      "\n",
      "  [Step 2/3] Writing to parquet with date partitioning...\n",
      "  ✓ Write completed successfully\n",
      "\n",
      "  [Step 3/3] Cleaning up...\n",
      "\n",
      "  [After write] Memory: 0.00 GB / 3.00 GB (0%)\n",
      "\n",
      "  ✓ Flight data saved successfully\n",
      "\n",
      "================================================================================\n",
      "[Preprocessing] Flight Data Preprocessing Pipeline - End\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "processedFlightData = [FL_DATE: date, OP_CARRIER_AIRLINE_ID: int ... 135 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[FL_DATE: date, OP_CARRIER_AIRLINE_ID: int ... 135 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import com.flightdelay.data.preprocessing.flights.FlightPreprocessingPipeline\n",
    "val processedFlightData = FlightPreprocessingPipeline.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce92b68-95d5-4056-9b7d-4a65bb21fd2b",
   "metadata": {},
   "source": [
    "## Check Flight Numbers after Join on WBAN (OK VALIDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "810cf82b-e6de-4ad3-bf82-1bee0c8e51ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rawWBANAirPortDFPath = /home/jovyan/work/output/common/data/raw_wban_airport_timezone.parquet\n",
       "rawWBANAirPortDF = [AirportID: int, WBAN: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[AirportID: int, WBAN: string ... 1 more field]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rawWBANAirPortDFPath = s\"${configuration.common.output.basePath}/common/data/raw_wban_airport_timezone.parquet\"\n",
    "val rawWBANAirPortDF = spark.read.parquet(rawWBANAirPortDFPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f0ebc2f-554f-47ef-87fd-9c8c3f1e3d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AirportID: integer (nullable = true)\n",
      " |-- WBAN: string (nullable = true)\n",
      " |-- TimeZone: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawWBANAirPortDF.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5655b67d-0d4f-4c55-a2d7-9343a8fb5e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== WBAN Coverage Report =====\n",
      "Total flights:                 486,133\n",
      "Missing ORIGIN flights:        12,377  (2.546%)\n",
      "Missing DEST flights:          12,387    (2.548%)\n",
      "Either origin/dest missing:    24,764  (5.094%)\n",
      "NULL ORIGIN_AIRPORT_ID:        0\n",
      "NULL DEST_AIRPORT_ID:          0\n",
      "\n",
      "Top 20 ORIGIN_AIRPORT_ID not in WBAN:\n",
      "+-----------------+\n",
      "|ORIGIN_AIRPORT_ID|\n",
      "+-----------------+\n",
      "|10135            |\n",
      "|10158            |\n",
      "|10165            |\n",
      "|10434            |\n",
      "|10599            |\n",
      "|10627            |\n",
      "|10643            |\n",
      "|10994            |\n",
      "|11003            |\n",
      "|11049            |\n",
      "|11076            |\n",
      "|11146            |\n",
      "|11617            |\n",
      "|11630            |\n",
      "|11973            |\n",
      "|11995            |\n",
      "|12016            |\n",
      "|12206            |\n",
      "|12448            |\n",
      "|12758            |\n",
      "+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Top 20 DEST_AIRPORT_ID not in WBAN:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "reportMissingAirports: (flights: org.apache.spark.sql.DataFrame, wbanAirports: org.apache.spark.sql.DataFrame)(implicit spark: org.apache.spark.sql.SparkSession)Unit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|DEST_AIRPORT_ID|\n",
      "+---------------+\n",
      "|10135          |\n",
      "|10158          |\n",
      "|10165          |\n",
      "|10434          |\n",
      "|10599          |\n",
      "|10627          |\n",
      "|10643          |\n",
      "|10994          |\n",
      "|11003          |\n",
      "|11049          |\n",
      "|11076          |\n",
      "|11146          |\n",
      "|11617          |\n",
      "|11630          |\n",
      "|11973          |\n",
      "|11995          |\n",
      "|12016          |\n",
      "|12206          |\n",
      "|12448          |\n",
      "|12758          |\n",
      "+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
    "\n",
    "// Hypothèse : rawFlightsDF et rawWBANAirPortDF sont déjà définis\n",
    "\n",
    "def reportMissingAirports(\n",
    "  flights: DataFrame,\n",
    "  wbanAirports: DataFrame\n",
    ")(implicit spark: SparkSession): Unit = {\n",
    "\n",
    "  // Référentiel distinct\n",
    "  val ref = wbanAirports.select(col(\"AirportID\")).distinct().cache()\n",
    "  val totalFlights = flights.count()\n",
    "\n",
    "  // Vols avec ORIGIN absent\n",
    "  val missingOriginFlights = flights\n",
    "    .filter(col(\"ORIGIN_AIRPORT_ID\").isNotNull)\n",
    "    .join(broadcast(ref), flights(\"ORIGIN_AIRPORT_ID\") === ref(\"AirportID\"), \"left_anti\")\n",
    "    .cache()\n",
    "\n",
    "  // Vols avec DEST absent\n",
    "  val missingDestFlights = flights\n",
    "    .filter(col(\"DEST_AIRPORT_ID\").isNotNull)\n",
    "    .join(broadcast(ref), flights(\"DEST_AIRPORT_ID\") === ref(\"AirportID\"), \"left_anti\")\n",
    "    .cache()\n",
    "\n",
    "  val cntMissingOrigin = missingOriginFlights.count()\n",
    "  val cntMissingDest   = missingDestFlights.count()\n",
    "\n",
    "  // Vols avec au moins un des deux manquant\n",
    "  val wOriginFlag = flights\n",
    "    .join(broadcast(ref).withColumn(\"ok_origin\", lit(true)),\n",
    "          flights(\"ORIGIN_AIRPORT_ID\") === ref(\"AirportID\"), \"left\")\n",
    "    .drop(ref(\"AirportID\"))\n",
    "\n",
    "  val wBothFlags = wOriginFlag\n",
    "    .join(broadcast(ref).withColumn(\"ok_dest\", lit(true)),\n",
    "          wOriginFlag(\"DEST_AIRPORT_ID\") === ref(\"AirportID\"), \"left\")\n",
    "    .drop(ref(\"AirportID\"))\n",
    "\n",
    "  val flagged = wBothFlags\n",
    "    .withColumn(\"missing_origin\", !coalesce(col(\"ok_origin\"), lit(false)))\n",
    "    .withColumn(\"missing_dest\",   !coalesce(col(\"ok_dest\"),   lit(false)))\n",
    "\n",
    "  val cntEitherMissing = flagged.filter(col(\"missing_origin\") || col(\"missing_dest\")).count()\n",
    "\n",
    "  val cntOriginNull = flights.filter(col(\"ORIGIN_AIRPORT_ID\").isNull).count()\n",
    "  val cntDestNull   = flights.filter(col(\"DEST_AIRPORT_ID\").isNull).count()\n",
    "\n",
    "  val missingOriginAirportIDs = missingOriginFlights\n",
    "    .select(\"ORIGIN_AIRPORT_ID\").distinct().orderBy(\"ORIGIN_AIRPORT_ID\")\n",
    "\n",
    "  val missingDestAirportIDs = missingDestFlights\n",
    "    .select(\"DEST_AIRPORT_ID\").distinct().orderBy(\"DEST_AIRPORT_ID\")\n",
    "\n",
    "  // === Affichage corrigé ===\n",
    "  println(\"\\n===== WBAN Coverage Report =====\")\n",
    "  println(f\"Total flights:                 $totalFlights%,d\")\n",
    "  println(f\"Missing ORIGIN flights:        $cntMissingOrigin%,d  (${cntMissingOrigin * 100.0 / totalFlights}%.3f%%)\")\n",
    "  println(f\"Missing DEST flights:          $cntMissingDest%,d    (${cntMissingDest * 100.0 / totalFlights}%.3f%%)\")\n",
    "  println(f\"Either origin/dest missing:    $cntEitherMissing%,d  (${cntEitherMissing * 100.0 / totalFlights}%.3f%%)\")\n",
    "  println(f\"NULL ORIGIN_AIRPORT_ID:        $cntOriginNull%,d\")\n",
    "  println(f\"NULL DEST_AIRPORT_ID:          $cntDestNull%,d\")\n",
    "\n",
    "  println(\"\\nTop 20 ORIGIN_AIRPORT_ID not in WBAN:\")\n",
    "  missingOriginAirportIDs.show(20, truncate = false)\n",
    "\n",
    "  println(\"Top 20 DEST_AIRPORT_ID not in WBAN:\")\n",
    "  missingDestAirportIDs.show(20, truncate = false)\n",
    "}\n",
    "\n",
    "// --- Appel ---\n",
    "reportMissingAirports(rawFlightsDF, rawWBANAirPortDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "729812c0-14ba-45d9-8cf8-650aa6b4037d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-347627"
     ]
    }
   ],
   "source": [
    "print(processedFlightData.count()-rawFlightsDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c07c0a-800f-4e7a-b276-3ad03f0be626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apache_toree_scala - Scala",
   "language": "scala",
   "name": "apache_toree_scala_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
