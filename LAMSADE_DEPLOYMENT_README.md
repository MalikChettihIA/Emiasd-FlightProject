# Flight Delay Prediction - LAMSADE Cluster Deployment

Ce workflow GitHub Actions automatise le d√©ploiement et l'ex√©cution de l'application Spark sur le cluster LAMSADE avec support pour JAR local.

## üöÄ Utilisation

### Pr√©paration du JAR local

**1. Build le JAR sur votre machine :**
```bash
./prepare-local-jar.sh
```
Ce script compile l'application et pr√©pare le JAR pour d√©ploiement.

**2. Options de d√©ploiement :**

#### Option A - Upload JAR local (recommand√©)
1. Allez sur : https://github.com/MalikChettihIA/Emiasd-FlightProject/actions
2. S√©lectionnez "Flight Delay Prediction - LAMSADE Cluster Deployment"
3. Cliquez "Run workflow"
4. Configurez :
   - **JAR source** : `upload`
   - **JAR path** : `target/scala-2.12/emiasd-flight-data-analysis_2.12-1.0.jar`
   - **Target environment** : `prod`
   - **Run on LAMSADE cluster** : ‚úÖ coch√©

#### Option B - Build automatique
- Choisissez **JAR source** : `build`
- Le workflow compilera automatiquement le JAR

### Configuration des Secrets GitHub

**Secrets requis :**
- `LAMSADE_SSH_KEY` : Votre cl√© SSH priv√©e
- `LAMSADE_USERNAME` : Votre nom d'utilisateur

## üìã Jobs du Workflow

### Job 1: Build JAR (conditionnel)
- Compile uniquement si "JAR source: build"
- G√©n√®re `emiasd-flight-data-analysis_2.12-1.0.jar`

### Job 1b: Upload JAR local (conditionnel)
- Utilise le JAR sp√©cifi√© dans "JAR path"
- V√©rifie que le fichier existe

### Job 2: Deploy to LAMSADE
- Upload JAR, donn√©es, d√©pendances MLflow
- Cr√©e les r√©pertoires HDFS
- Upload vers HDFS

### Job 3: Run on LAMSADE
- Soumet le job Spark avec YARN
- T√©l√©charge les r√©sultats

### Job 4: Local Pipeline
- Pipeline Docker pour d√©veloppement

## üõ†Ô∏è Scripts utilitaires

### `prepare-local-jar.sh`
Pr√©pare le JAR local pour d√©ploiement :
```bash
./prepare-local-jar.sh
```

### `upload-jar-to-github.sh`
Upload automatique vers GitHub Actions :
```bash
./upload-jar-to-github.sh target/scala-2.12/emiasd-flight-data-analysis_2.12-1.0.jar
```

### `deploy-to-lamsade.sh`
Test de connexion au cluster :
```bash
./deploy-to-lamsade.sh ~/.ssh/lamsade_key username
```
- Soumet le job Spark sur le cluster avec YARN
- Configuration Spark optimis√©e pour le cluster :
  ```bash
  --master yarn
  --deploy-mode cluster
  --executor-cores 4
  --executor-memory 4G
  --num-executors 3
  ```
- T√©l√©charge les r√©sultats depuis HDFS
- **Artefact** : `lamsade-results`

### Job 4: Local Pipeline (par d√©faut)
- Ex√©cute le pipeline complet en local avec Docker
- Utilise le cluster Spark local
- **Artefact** : `local-results`

## üîß Configuration Spark pour LAMSADE

Le workflow utilise ces param√®tres Spark optimis√©s pour le cluster LAMSADE :

```yaml
--master yarn                    # Utilise YARN comme gestionnaire de ressources
--deploy-mode cluster           # Mode cluster pour meilleure scalabilit√©
--executor-cores 4              # 4 c≈ìurs par executor
--executor-memory 4G            # 4GB RAM par executor
--num-executors 3               # 3 executors
--driver-memory 2G              # 2GB pour le driver
--driver-cores 2                # 2 c≈ìurs pour le driver
```

## üìä Artefacts G√©n√©r√©s

Apr√®s ex√©cution, vous pouvez t√©l√©charger :

- **flight-delay-app-jar** : JAR de l'application
- **lamsade-results** : R√©sultats du cluster LAMSADE
- **local-results** : R√©sultats du pipeline local

## üîç Monitoring

### Interface Spark UI
Pour monitorer vos jobs sur le cluster LAMSADE :
```
http://vmhadoopmaster.cluster.lamsade.dauphine.fr:8088
```

### Acc√®s SSH direct
Vous pouvez toujours acc√©der directement au cluster :
```bash
ssh -p 5022 -i votre_cle_ssh votre_username@ssh.lamsade.dauphine.fr
```

## üõ†Ô∏è D√©pannage

### Probl√®mes SSH
- V√©rifiez que votre cl√© SSH est correctement configur√©e dans les secrets
- Assurez-vous que la cl√© n'a pas de passphrase
- V√©rifiez les permissions de la cl√© (600)

### Probl√®mes HDFS
- V√©rifiez que votre r√©pertoire utilisateur existe : `/students/p6emiasd2025/votre_username/`
- V√©rifiez les quotas HDFS si n√©cessaire

### Probl√®mes Spark
- Consultez les logs YARN via l'interface web
- V√©rifiez la disponibilit√© des ressources cluster
- Ajustez les param√®tres Spark si n√©cessaire

## üìù Notes Importantes

- Le workflow utilise `--deploy-mode cluster` pour une meilleure isolation
- Les donn√©es sont automatiquement upload√©es vers HDFS
- MLflow est configur√© pour fonctionner avec le cluster
- Le timeout d'attente des jobs est de 30 minutes maximum

## üìù Workflow Modes

| Mode | JAR Source | Cluster | Usage |
|------|------------|---------|-------|
| **Local Dev** | build | ‚ùå | D√©veloppement local |
| **Local JAR** | upload | ‚ùå | Test JAR local |
| **LAMSADE Auto** | build | ‚úÖ | CI/CD complet |
| **LAMSADE JAR** | upload | ‚úÖ | D√©ploiement JAR local |

---

**üéØ R√©sultat** : Build local + d√©ploiement one-click sur LAMSADE ! üöÄ