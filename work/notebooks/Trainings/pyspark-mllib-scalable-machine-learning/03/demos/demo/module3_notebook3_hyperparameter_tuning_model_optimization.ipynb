{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f24e7ce-ba21-4cde-8b52-9d03e0e379a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Module 3 Notebook 3: Hyperparameter Tuning and Model Optimization\n",
    "\n",
    "In this notebook, we'll focus on optimizing the Linear Regression model we trained in Notebook 2 to predict `total_purchase_amount`. We'll use hyperparameter tuning with Cross-Validation to find the best model configuration and potentially improve its predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59ea16e2-74d4-4470-9c3c-132b7f89630e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression, LinearRegressionModel\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d11d7f17-196b-43b7-b1d1-e153f6a8198d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Load Data\n",
    "\n",
    "First, we load the pre-processed training and testing datasets created in Module 2, specifically for the regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b23544c-02b1-4d01-8739-126e2e787c40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Training Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>customer_id</th><th>product_id</th><th>features</th><th>total_purchase_amount</th></tr></thead><tbody><tr><td>1</td><td>154</td><td>Map(vectorType -> sparse, length -> 27, indices -> List(0, 1, 2, 3, 4, 7, 11, 12, 16, 24), values -> List(0.3548387096774194, 0.2552140504939627, 3.9096937406569814E-4, 0.6551724137931034, 0.1875, 0.5, 0.15797645978130034, 0.6551724137931034, 1.0, 1.0))</td><td>41.26</td></tr><tr><td>4</td><td>244</td><td>Map(vectorType -> sparse, length -> 27, indices -> List(0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 17), values -> List(0.564516129032258, 0.22420417124039518, 0.043811568093832645, 0.4137931034482758, 0.3125, 0.5, 0.5, 0.3333333333333333, 0.01304181051016494, 1.603082406851895E-5, 0.6516631232308321, 0.4137931034482758, 1.0, 1.0))</td><td>137.89</td></tr><tr><td>6</td><td>373</td><td>Map(vectorType -> sparse, length -> 27, indices -> List(0, 1, 2, 3, 4, 7, 9, 11, 12, 13, 14, 18), values -> List(0.22580645161290322, 0.0570801317233809, 0.061044884817355975, 0.5862068965517241, 0.125, 0.5, 0.009589566551591868, 0.9311661982921617, 0.5862068965517241, 1.0, 1.0, 1.0))</td><td>112.2</td></tr><tr><td>7</td><td>58</td><td>Map(vectorType -> sparse, length -> 27, indices -> List(0, 1, 2, 3, 4, 7, 9, 11, 12, 15, 17), values -> List(0.564516129032258, 0.2897914379802415, 0.08802943769404731, 0.5172413793103449, 0.3125, 0.5, 0.01649405446873801, 0.568094947294946, 0.5172413793103449, 1.0, 1.0))</td><td>219.74</td></tr><tr><td>7</td><td>222</td><td>Map(vectorType -> sparse, length -> 27, indices -> List(0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 15, 19), values -> List(0.564516129032258, 0.2897914379802415, 0.021342328184292228, 0.2758620689655172, 0.4375, 0.5, 0.5, 0.3333333333333333, 0.01457614115841964, 1.803467707708382E-5, 0.6960536549098333, 0.2758620689655172, 1.0, 1.0))</td><td>106.71</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         154,
         {
          "indices": [
           0,
           1,
           2,
           3,
           4,
           7,
           11,
           12,
           16,
           24
          ],
          "length": 27,
          "values": [
           0.3548387096774194,
           0.2552140504939627,
           0.00039096937406569814,
           0.6551724137931034,
           0.1875,
           0.5,
           0.15797645978130034,
           0.6551724137931034,
           1,
           1
          ],
          "vectorType": "sparse"
         },
         41.26
        ],
        [
         4,
         244,
         {
          "indices": [
           0,
           1,
           2,
           3,
           4,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           14,
           17
          ],
          "length": 27,
          "values": [
           0.564516129032258,
           0.22420417124039518,
           0.043811568093832645,
           0.4137931034482758,
           0.3125,
           0.5,
           0.5,
           0.3333333333333333,
           0.01304181051016494,
           1.603082406851895e-05,
           0.6516631232308321,
           0.4137931034482758,
           1,
           1
          ],
          "vectorType": "sparse"
         },
         137.89
        ],
        [
         6,
         373,
         {
          "indices": [
           0,
           1,
           2,
           3,
           4,
           7,
           9,
           11,
           12,
           13,
           14,
           18
          ],
          "length": 27,
          "values": [
           0.22580645161290322,
           0.0570801317233809,
           0.061044884817355975,
           0.5862068965517241,
           0.125,
           0.5,
           0.009589566551591868,
           0.9311661982921617,
           0.5862068965517241,
           1,
           1,
           1
          ],
          "vectorType": "sparse"
         },
         112.2
        ],
        [
         7,
         58,
         {
          "indices": [
           0,
           1,
           2,
           3,
           4,
           7,
           9,
           11,
           12,
           15,
           17
          ],
          "length": 27,
          "values": [
           0.564516129032258,
           0.2897914379802415,
           0.08802943769404731,
           0.5172413793103449,
           0.3125,
           0.5,
           0.01649405446873801,
           0.568094947294946,
           0.5172413793103449,
           1,
           1
          ],
          "vectorType": "sparse"
         },
         219.74
        ],
        [
         7,
         222,
         {
          "indices": [
           0,
           1,
           2,
           3,
           4,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           15,
           19
          ],
          "length": 27,
          "values": [
           0.564516129032258,
           0.2897914379802415,
           0.021342328184292228,
           0.2758620689655172,
           0.4375,
           0.5,
           0.5,
           0.3333333333333333,
           0.01457614115841964,
           1.803467707708382e-05,
           0.6960536549098333,
           0.2758620689655172,
           1,
           1
          ],
          "vectorType": "sparse"
         },
         106.71
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "customer_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "product_id",
         "type": "\"long\""
        },
        {
         "metadata": "{\"ml_attr\":{\"attrs\":{\"numeric\":[{\"idx\":0,\"name\":\"numerical_features_scaled_scaled_numerical_features_0\"},{\"idx\":1,\"name\":\"numerical_features_scaled_scaled_numerical_features_1\"},{\"idx\":2,\"name\":\"numerical_features_scaled_scaled_numerical_features_2\"},{\"idx\":3,\"name\":\"numerical_features_scaled_scaled_numerical_features_3\"},{\"idx\":4,\"name\":\"numerical_features_scaled_scaled_numerical_features_4\"},{\"idx\":5,\"name\":\"numerical_features_scaled_scaled_numerical_features_5\"},{\"idx\":6,\"name\":\"numerical_features_scaled_scaled_numerical_features_6\"},{\"idx\":7,\"name\":\"numerical_features_scaled_scaled_numerical_features_7\"},{\"idx\":8,\"name\":\"numerical_features_scaled_scaled_numerical_features_8\"},{\"idx\":9,\"name\":\"numerical_features_scaled_scaled_numerical_features_9\"},{\"idx\":10,\"name\":\"numerical_features_scaled_scaled_numerical_features_10\"},{\"idx\":11,\"name\":\"numerical_features_scaled_scaled_numerical_features_11\"},{\"idx\":12,\"name\":\"numerical_features_scaled_scaled_numerical_features_12\"}],\"binary\":[{\"idx\":13,\"name\":\"selected_ohe_features_country_vec_DE\"},{\"idx\":14,\"name\":\"selected_ohe_features_membership_level_vec_Bronze\"},{\"idx\":15,\"name\":\"selected_ohe_features_membership_level_vec_Gold\"},{\"idx\":16,\"name\":\"selected_ohe_features_membership_level_vec_Platinum\"},{\"idx\":17,\"name\":\"selected_ohe_features_category_vec_Sports\"},{\"idx\":18,\"name\":\"selected_ohe_features_category_vec_Health\"},{\"idx\":19,\"name\":\"selected_ohe_features_category_vec_Beauty\"},{\"idx\":20,\"name\":\"selected_ohe_features_category_vec_Toys\"},{\"idx\":21,\"name\":\"selected_ohe_features_category_vec_Automotive\"},{\"idx\":22,\"name\":\"selected_ohe_features_category_vec_Clothing\"},{\"idx\":23,\"name\":\"selected_ohe_features_category_vec_Home & Kitchen\"},{\"idx\":24,\"name\":\"selected_ohe_features_category_vec_Books\"},{\"idx\":25,\"name\":\"selected_ohe_features_category_vec_Grocery\"},{\"idx\":26,\"name\":\"selected_ohe_features_category_vec_Electronics\"}]},\"num_attrs\":27}}",
         "name": "features",
         "type": "{\"type\":\"udt\",\"class\":\"org.apache.spark.ml.linalg.VectorUDT\",\"pyClass\":\"pyspark.ml.linalg.VectorUDT\",\"sqlType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"type\",\"type\":\"byte\",\"nullable\":false,\"metadata\":{}},{\"name\":\"size\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"indices\",\"type\":{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}},{\"name\":\"values\",\"type\":{\"type\":\"array\",\"elementType\":\"double\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}}]}}"
        },
        {
         "metadata": "{}",
         "name": "total_purchase_amount",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load training and testing data\n",
    "train_data = spark.table(\"ecommerce.regression_train_features\")\n",
    "test_data = spark.table(\"ecommerce.regression_test_features\")\n",
    "\n",
    "print(\"\\nSample Training Data:\")\n",
    "train_data.select(\"customer_id\", \"product_id\", \"features\", \"total_purchase_amount\").limit(5).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86a7c11b-e0ea-4ddf-a538-20f1810e226c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Baseline Model Recap\n",
    "\n",
    "Let's quickly re-evaluate the baseline Linear Regression model (from Notebook 2) on the test set to establish a performance benchmark before tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54e0039d-4cd7-4226-b897-bb996ea1beae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4441289d1adf4a09b130d55ea7efd20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc0a4f6307d4512a07bc246624ee4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Baseline Model Performance ---\n",
      "Training Time: 33.26 seconds\n",
      "RMSE: 25.81\n",
      "MAE: 12.70\n",
      "R2: 0.9911\n"
     ]
    }
   ],
   "source": [
    "# Define a baseline Linear Regression model\n",
    "lr_baseline = LinearRegression(featuresCol=\"features\", labelCol=\"total_purchase_amount\")\n",
    "\n",
    "# Train the baseline model\n",
    "start_time_baseline = time.time()\n",
    "lr_baseline_model = lr_baseline.fit(train_data)\n",
    "end_time_baseline = time.time()\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_baseline = lr_baseline_model.transform(test_data)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"total_purchase_amount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_mae = RegressionEvaluator(labelCol=\"total_purchase_amount\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"total_purchase_amount\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "rmse_baseline = evaluator_rmse.evaluate(predictions_baseline)\n",
    "mae_baseline = evaluator_mae.evaluate(predictions_baseline)\n",
    "r2_baseline = evaluator_r2.evaluate(predictions_baseline)\n",
    "\n",
    "print(\"--- Baseline Model Performance ---\")\n",
    "print(f\"Training Time: {end_time_baseline - start_time_baseline:.2f} seconds\")\n",
    "print(f\"RMSE: {rmse_baseline:.2f}\")\n",
    "print(f\"MAE: {mae_baseline:.2f}\")\n",
    "print(f\"R2: {r2_baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecd0ebd9-164f-4ec9-8b5d-f216c6723df0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Hyperparameter Tuning with CrossValidator\n",
    "\n",
    "Now, we set up the hyperparameter tuning process using `CrossValidator`. This involves:\n",
    "1.  **Estimator:** Defining the model we want to tune (Linear Regression).\n",
    "2.  **Parameter Grid:** Specifying the hyperparameters and the range of values to test.\n",
    "3.  **Evaluator:** Defining the metric used to compare model performance (RMSE).\n",
    "4.  **CrossValidator Setup:** Configuring the number of folds (splits of the training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54af0eb3-86b9-489c-a635-29a0a5127a52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameter combinations to test: 18\n",
      "CrossValidator configured. Ready for training...\n"
     ]
    }
   ],
   "source": [
    "# 1. Define the Estimator\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"total_purchase_amount\")\n",
    "\n",
    "# 2. Define the Parameter Grid\n",
    "# We'll test combinations of regularization strength and the L1/L2 mix.\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.maxIter, [10, 20]) \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 0.5]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "print(f\"Number of parameter combinations to test: {len(paramGrid)}\") # 2 * 3 * 3 = 18 combinations\n",
    "\n",
    "# 3. Define the Evaluator\n",
    "# We'll use RMSE as the primary metric for optimization.\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"total_purchase_amount\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "# 4. Setup CrossValidator\n",
    "# We use 3 folds for a balance between robustness and computation time.\n",
    "cv = CrossValidator(\n",
    "    estimator=lr, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=evaluator, \n",
    "    numFolds=3, # K=3 folds\n",
    "    seed=42 # For reproducibility\n",
    ")\n",
    "\n",
    "print(\"CrossValidator configured. Ready for training...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9472f6b-f97b-4bb4-a2fc-e0491c4e9880",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Fit CrossValidator\n",
    "\n",
    "Now we train the `CrossValidator` on the training data. This will train multiple Linear Regression models (Number of Folds Ã— Number of Parameter Combinations) and evaluate them using the specified evaluator (RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa1e3a07-a08b-44a3-9449-a5e3529caba7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CrossValidator fitting...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9adbe4c1d054aaaa308945056264b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821e2763e335488f950513706b17d3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0be8e46e79416cadaa68b1dbe59b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790857b639e44e4698ad1279c3744b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValidator fitting finished in 105.18 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Train the CrossValidator model\n",
    "# This will run 3 * 18 = 54 training jobs in total.\n",
    "print(\"Starting CrossValidator fitting...\")\n",
    "start_time_cv = time.time()\n",
    "cvModel = cv.fit(train_data)\n",
    "end_time_cv = time.time()\n",
    "print(f\"CrossValidator fitting finished in {end_time_cv - start_time_cv:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3febef5d-5287-49c7-9b14-cc0be7e773af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. Analyze Tuning Results\n",
    "\n",
    "After fitting, we can extract the best model found by the `CrossValidator` and examine the optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66034ed9-3afd-43f3-ad4b-4dd4a7e4d626",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best Model Parameters ---\n",
      "MaxIter: 20\n",
      "RegParam: 0.01\n",
      "ElasticNetParam: 1.0\n",
      "\n",
      "--- Average RMSE per Parameter Combination (across folds) ---\n",
      "  maxIter=20, regParam=0.01, elasticNetParam=1.0 -> Avg RMSE: 27.8287\n",
      "  maxIter=20, regParam=0.01, elasticNetParam=0.5 -> Avg RMSE: 27.8288\n",
      "  maxIter=10, regParam=0.1, elasticNetParam=0.0 -> Avg RMSE: 27.8288\n",
      "  maxIter=20, regParam=0.1, elasticNetParam=0.0 -> Avg RMSE: 27.8288\n",
      "  maxIter=10, regParam=0.01, elasticNetParam=0.0 -> Avg RMSE: 27.8293\n"
     ]
    }
   ],
   "source": [
    "# Get the best model from CrossValidation\n",
    "bestModel = cvModel.bestModel\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"--- Best Model Parameters ---\")\n",
    "print(f\"MaxIter: {bestModel.getMaxIter()}\")\n",
    "print(f\"RegParam: {bestModel.getRegParam()}\")\n",
    "print(f\"ElasticNetParam: {bestModel.getElasticNetParam()}\")\n",
    "\n",
    "# You can also examine the average metrics across folds for each parameter combination\n",
    "# Combine parameters and metrics for easier viewing\n",
    "avg_metrics = cvModel.avgMetrics\n",
    "param_maps = cvModel.getEstimatorParamMaps()\n",
    "\n",
    "print(\"\\n--- Average RMSE per Parameter Combination (across folds) ---\")\n",
    "results = []\n",
    "for params, metric in zip(param_maps, avg_metrics):\n",
    "    results.append((\n",
    "        params[lr.maxIter], \n",
    "        params[lr.regParam], \n",
    "        params[lr.elasticNetParam], \n",
    "        metric\n",
    "    ))\n",
    "\n",
    "# Sort results by RMSE (lower is better)\n",
    "results.sort(key=lambda x: x[3])\n",
    "\n",
    "for iter_val, reg_param, enet_param, rmse_val in results[:5]: # Show top 5\n",
    "    print(f\"  maxIter={iter_val}, regParam={reg_param}, elasticNetParam={enet_param} -> Avg RMSE: {rmse_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a6e8c36-d3c3-4f44-a274-ef5622a2a6b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6. Evaluate Tuned Model\n",
    "\n",
    "Finally, we evaluate the performance of the *best model* (selected through cross-validation) on the held-out *test* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b83a4744-2079-4b9f-a491-7a2c7f3f0222",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tuned Model Performance (on Test Set) ---\n",
      "RMSE: 25.81\n",
      "MAE: 12.70\n",
      "R2: 0.9911\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data using the best model\n",
    "predictions_tuned = bestModel.transform(test_data)\n",
    "\n",
    "# Evaluate the tuned model using the same evaluators\n",
    "rmse_tuned = evaluator_rmse.evaluate(predictions_tuned)\n",
    "mae_tuned = evaluator_mae.evaluate(predictions_tuned)\n",
    "r2_tuned = evaluator_r2.evaluate(predictions_tuned)\n",
    "\n",
    "print(\"--- Tuned Model Performance (on Test Set) ---\")\n",
    "print(f\"RMSE: {rmse_tuned:.2f}\")\n",
    "print(f\"MAE: {mae_tuned:.2f}\")\n",
    "print(f\"R2: {r2_tuned:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6921908-d6b8-4ef5-b297-2e0be0ff8fee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 7. Compare and Conclude\n",
    "\n",
    "Let's compare the performance of the tuned model against the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "514f1921-44aa-4031-b578-9ad346b6cca7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Performance Comparison --- Gherkin table format ---\n",
      "| Metric | Baseline Model | Tuned Model |\n",
      "|--------|----------------|-------------|\n",
      "| RMSE   | 25.81          | 25.81       |\n",
      "| MAE    | 12.70          | 12.70       |\n",
      "| R2     | 0.9911         | 0.9911      |\n",
      "\n",
      "Discussion:\n",
      "Hyperparameter tuning aimed to find the optimal settings for the Linear Regression model.\n",
      "By exploring different values for maxIter, regParam, and elasticNetParam using 3-fold cross-validation, we identified a configuration that performs best according to the RMSE metric on the validation folds.\n",
      "Comparing the tuned model's performance on the held-out test set to the baseline model:\n",
      "- The tuned model performed slightly worse or the same as the baseline on the test set. This can sometimes occur due to the randomness in cross-validation splits or if the chosen parameter grid didn't contain better options than the default. The baseline model was already quite strong.\n",
      "Even small improvements can be valuable, and the tuning process provides confidence that we've explored reasonable model configurations.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Performance Comparison --- Gherkin table format ---\")\n",
    "print(\"| Metric | Baseline Model | Tuned Model |\")\n",
    "print(\"|--------|----------------|-------------|\")\n",
    "print(f\"| RMSE   | {rmse_baseline:<14.2f} | {rmse_tuned:<11.2f} |\")\n",
    "print(f\"| MAE    | {mae_baseline:<14.2f} | {mae_tuned:<11.2f} |\")\n",
    "print(f\"| R2     | {r2_baseline:<14.4f} | {r2_tuned:<11.4f} |\")\n",
    "\n",
    "# Discussion based on typical results\n",
    "print(\"\\nDiscussion:\")\n",
    "print(\"Hyperparameter tuning aimed to find the optimal settings for the Linear Regression model.\")\n",
    "print(f\"By exploring different values for maxIter, regParam, and elasticNetParam using {cv.getNumFolds()}-fold cross-validation, we identified a configuration that performs best according to the RMSE metric on the validation folds.\")\n",
    "print(\"Comparing the tuned model's performance on the held-out test set to the baseline model:\")\n",
    "if rmse_tuned < rmse_baseline:\n",
    "    print(\"- The tuned model shows an improvement in RMSE, indicating better predictive accuracy on average.\")\n",
    "    print(\"- The MAE likely also improved, suggesting smaller average prediction errors.\")\n",
    "    print(\"- The R-squared value might be slightly higher, explaining a tiny bit more variance.\")\n",
    "    print(\"Overall, the tuning process successfully refined the model, leading to more reliable purchase amount predictions.\")\n",
    "elif rmse_tuned == rmse_baseline:\n",
    "     print(\"- The tuned model's performance is identical to the baseline. This might happen if the default parameters were already near optimal for this dataset, or if the search grid didn't contain significantly better configurations.\")\n",
    "else:\n",
    "    print(\"- The tuned model performed slightly worse or the same as the baseline on the test set. This can sometimes occur due to the randomness in cross-validation splits or if the chosen parameter grid didn't contain better options than the default. The baseline model was already quite strong.\")\n",
    "print(\"Even small improvements can be valuable, and the tuning process provides confidence that we've explored reasonable model configurations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "293427e0-01ec-4eaa-8428-8c11814c2bad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 8. Model Persistence\n",
    "\n",
    "Now that we have identified the best model through hyperparameter tuning, we should save it for future use (e.g., deployment, batch predictions). We save the trained `LinearRegressionModel` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "994a64cb-a6bf-4d5d-aba7-3c2837d417b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best tuned Linear Regression model saved to: dbfs:/Workspace/Users/war_che@hotmail.com/PySpark MLlib/models/tuned_linear_regression_model\n",
      "\n",
      "Successfully loaded the saved model.\n",
      "Loaded Model MaxIter: 20\n",
      "Loaded Model RegParam: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Define the path to save the model\n",
    "model_save_path = \"dbfs:/Workspace/Users/war_che@hotmail.com/PySpark MLlib/models/tuned_linear_regression_model\"\n",
    "\n",
    "# Save the best model\n",
    "bestModel.write().overwrite().save(model_save_path)\n",
    "\n",
    "print(f\"Best tuned Linear Regression model saved to: {model_save_path}\")\n",
    "\n",
    "# Demonstrate loading the model back (optional)\n",
    "try:\n",
    "    loaded_model = LinearRegressionModel.load(model_save_path)\n",
    "    print(\"\\nSuccessfully loaded the saved model.\")\n",
    "    print(f\"Loaded Model MaxIter: {loaded_model.getMaxIter()}\")\n",
    "    print(f\"Loaded Model RegParam: {loaded_model.getRegParam()}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError loading the model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01570a7d-129c-4617-8819-9fd7ca225d0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "In this notebook, we successfully:\n",
    "1. Loaded the pre-processed regression data.\n",
    "2. Established a baseline performance using the default Linear Regression model.\n",
    "3. Configured and executed hyperparameter tuning using `CrossValidator` with a `ParamGridBuilder` and `RegressionEvaluator`.\n",
    "4. Identified the best set of hyperparameters (`maxIter`, `regParam`, `elasticNetParam`) based on cross-validated RMSE.\n",
    "5. Evaluated the optimized model on the test set and compared its performance to the baseline.\n",
    "6. Saved the best tuned model for future use.\n",
    "\n",
    "This concludes Module 3 on training and evaluating models. In Module 4, we will focus on building end-to-end ML Pipelines, integrating all the steps from data loading and feature engineering to model training and persistence."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "module3_notebook3_hyperparameter_tuning_model_optimization",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
