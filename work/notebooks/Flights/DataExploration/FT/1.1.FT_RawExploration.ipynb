{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a137a405-aed5-4fb7-87b5-eeee85e6140c",
   "metadata": {},
   "source": [
    "# Weather Dataset Preprocessing and feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53e4989d-8472-46e5-b806-ddde048d91f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached version of Emiasd-Flight-Data-Analysis.jar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "error: error while loading FlightDataLoader, class file '/tmp/toree-tmp-dir2537429693683601932/toree_add_jars/Emiasd-Flight-Data-Analysis.jar(com/flightdelay/data/loaders/FlightDataLoader.class)' has location not matching its contents: contains class FlightDataLoader\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached version of Emiasd-Flight-Data-Analysis.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar file:///home/jovyan/work/apps/Emiasd-Flight-Data-Analysis.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c5e2137-c51d-4b08-89fc-72273d7e9841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "args = Array(jupyter)\n",
       "spark = org.apache.spark.sql.SparkSession@2a0c6123\n",
       "session = org.apache.spark.sql.SparkSession@2a0c6123\n",
       "configuration = AppConfiguration(local,CommonConfig(42,DataConfig(/home/jovyan/work/data,FileConfig(/home/jovyan/work/data/FLIGHT-3Y/Flights/*.csv),FileConfig(/home/jovyan/work/data/FLIGHT-3Y/Weather/*.txt),FileConfig(/home/jovyan/work/data/FLIGHT-3Y/wban_airport_timezone.csv)),OutputConfig(/home/jovyan/work/output,FileConfig(/home/jovyan/work/output/data),FileConfig(/home/jovya...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "AppConfiguration(local,CommonConfig(42,DataConfig(/home/jovyan/work/data,FileConfig(/home/jovyan/work/data/FLIGHT-3Y/Flights/*.csv),FileConfig(/home/jovyan/work/data/FLIGHT-3Y/Weather/*.txt),FileConfig(/home/jovyan/work/data/FLIGHT-3Y/wban_airport_timezone.csv)),OutputConfig(/home/jovyan/work/output,FileConfig(/home/jovyan/work/output/data),FileConfig(/home/jovya..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import com.flightdelay.config.{AppConfiguration, ConfigurationLoader}\n",
    "import com.flightdelay.data.loaders.FlightDataLoader\n",
    "\n",
    "//Env Configuration\n",
    "val args: Array[String] = Array(\"jupyter\")\n",
    "\n",
    "val spark = SparkSession.builder()\n",
    "  .config(sc.getConf)\n",
    "  .getOrCreate()\n",
    "\n",
    "// Rendre la session Spark implicite\n",
    "implicit val session = spark\n",
    "implicit val configuration: AppConfiguration = ConfigurationLoader.loadConfiguration(args)\n",
    "\n",
    "val rawFlightsPath = s\"${configuration.common.output.basePath}/common/data/raw_flights.parquet\"\n",
    "val flightsDF = spark.read.parquet(rawFlightsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bc773cd-c5e5-49c5-9fd7-42113bee1b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEFAULT_DATE_FORMAT = yyyy-MM-dd\n",
       "csvRawFlightsPath = /home/jovyan/work/data/FLIGHT-3Y/Flights/*.csv\n",
       "df = [FL_DATE: date, OP_CARRIER_AIRLINE_ID: int ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "expectedSchema: org.apache.spark.sql.types.StructType\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[FL_DATE: date, OP_CARRIER_AIRLINE_ID: int ... 10 more fields]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val DEFAULT_DATE_FORMAT = \"yyyy-MM-dd\"\n",
    "def expectedSchema: StructType = StructType(Array(\n",
    "    StructField(\"FL_DATE\", StringType, nullable = false),\n",
    "    StructField(\"OP_CARRIER_AIRLINE_ID\", IntegerType, nullable = false),\n",
    "    StructField(\"OP_CARRIER_FL_NUM\", IntegerType, nullable = false),\n",
    "    StructField(\"ORIGIN_AIRPORT_ID\", IntegerType, nullable = false),\n",
    "    StructField(\"DEST_AIRPORT_ID\", IntegerType, nullable = false),\n",
    "    StructField(\"CRS_DEP_TIME\", IntegerType, nullable = false),\n",
    "    StructField(\"ARR_DELAY_NEW\", DoubleType, nullable = true),\n",
    "    StructField(\"CANCELLED\", IntegerType, nullable = true),\n",
    "    StructField(\"DIVERTED\", IntegerType, nullable = true),\n",
    "    StructField(\"CRS_ELAPSED_TIME\", DoubleType, nullable = true),\n",
    "    StructField(\"WEATHER_DELAY\", DoubleType, nullable = true),\n",
    "    StructField(\"NAS_DELAY\", DoubleType, nullable = true)\n",
    "  ))\n",
    "\n",
    "val csvRawFlightsPath = s\"${configuration.common.data.basePath}/FLIGHT-3Y/Flights/*.csv\"\n",
    "val df = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .schema(expectedSchema)\n",
    "  .option(\"timestampFormat\", DEFAULT_DATE_FORMAT)\n",
    "  .option(\"multiline\", \"true\")\n",
    "  .option(\"escape\", \"\\\"\")\n",
    "  .load(csvRawFlightsPath)\n",
    "  .withColumn(\"FL_DATE\", to_date(col(\"FL_DATE\"), DEFAULT_DATE_FORMAT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd7d6de1-9abc-49e3-b148-f41573966d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18286055"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2940aa8-c1c2-4034-87eb-51fb7d8fab64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18286055"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightsDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f45dd1-1883-4e19-aab7-cc3571743db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: date (nullable = true)\n",
      " |-- OP_CARRIER_AIRLINE_ID: integer (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n",
      " |-- ORIGIN_AIRPORT_ID: integer (nullable = true)\n",
      " |-- DEST_AIRPORT_ID: integer (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- ARR_DELAY_NEW: double (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
      " |-- WEATHER_DELAY: double (nullable = true)\n",
      " |-- NAS_DELAY: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsDF.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21d40652-8fb6-491a-89fe-532daa6bffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.ml.feature.{StringIndexer, OneHotEncoder, VectorAssembler}\n",
    "import scala.util.Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42c40185-a887-4153-b476-2f6577bdc6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------+-----------------+-----------------+---------------+------------+-------------+---------+--------+----------------+-------------+---------+\n",
      "|   FL_DATE|OP_CARRIER_AIRLINE_ID|OP_CARRIER_FL_NUM|ORIGIN_AIRPORT_ID|DEST_AIRPORT_ID|CRS_DEP_TIME|ARR_DELAY_NEW|CANCELLED|DIVERTED|CRS_ELAPSED_TIME|WEATHER_DELAY|NAS_DELAY|\n",
      "+----------+---------------------+-----------------+-----------------+---------------+------------+-------------+---------+--------+----------------+-------------+---------+\n",
      "|2013-07-01|                20363|             3407|            11433|          13342|        1040|          0.0|     NULL|    NULL|            79.0|         NULL|     NULL|\n",
      "|2013-07-01|                20363|             3409|            11433|          12266|        1227|          0.0|     NULL|    NULL|           175.0|         NULL|     NULL|\n",
      "|2013-07-01|                20363|             3848|            13485|          11433|         900|          2.0|     NULL|    NULL|            77.0|         NULL|     NULL|\n",
      "|2013-07-01|                20363|             3851|            11433|          11066|        1535|          0.0|     NULL|    NULL|            60.0|         NULL|     NULL|\n",
      "|2013-07-01|                20363|             3852|            10627|          13487|         500|          0.0|     NULL|    NULL|            82.0|         NULL|     NULL|\n",
      "|2013-07-01|                20363|             3854|            13198|          11193|         800|          0.0|     NULL|    NULL|           102.0|         NULL|     NULL|\n",
      "|2013-07-01|                20363|             3855|            10792|          11433|        1720|         18.0|     NULL|    NULL|            78.0|          0.0|     12.0|\n",
      "|2013-07-01|                20363|             3855|            11433|          10792|        1541|          7.0|     NULL|    NULL|            73.0|         NULL|     NULL|\n",
      "|2013-07-01|                20363|             3859|            10397|          12264|         830|        113.0|     NULL|    NULL|           114.0|          0.0|     19.0|\n",
      "|2013-07-01|                20363|             3859|            12264|          10397|         600|        112.0|     NULL|    NULL|           106.0|          0.0|      4.0|\n",
      "+----------+---------------------+-----------------+-----------------+---------------+------------+-------------+---------+--------+----------------+-------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed49521e-a731-4973-87fc-b2910d84a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|CANCELLED|\n",
      "+---------+\n",
      "|     NULL|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsDF.select(\"CANCELLED\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bff86cb-0f14-4593-84c4-5942b5d7522a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|DIVERTED|\n",
      "+--------+\n",
      "|    NULL|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsDF.select(\"DIVERTED\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd1e0f-3488-4bb4-8193-5434f3dda3cc",
   "metadata": {},
   "source": [
    "## 1. OP_CARRIER_AIRLINE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "225697d2-27e6-497e-809e-be1029437db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightsDF.select(\"OP_CARRIER_AIRLINE_ID\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd5a223f-d961-48ab-a6c3-475ea5c87d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|OP_CARRIER_AIRLINE_ID|\n",
      "+---------------------+\n",
      "|                20398|\n",
      "|                19690|\n",
      "|                20409|\n",
      "|                20378|\n",
      "|                19790|\n",
      "|                20304|\n",
      "|                20436|\n",
      "|                19393|\n",
      "|                20355|\n",
      "|                19805|\n",
      "|                19930|\n",
      "|                20366|\n",
      "|                19977|\n",
      "|                21171|\n",
      "|                20437|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsDF.select(\"OP_CARRIER_AIRLINE_ID\").distinct().show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d50da29f-aa2f-456e-8ea1-cc2e700bfb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6670"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightsDF.select(\"OP_CARRIER_FL_NUM\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d305213-d53a-4202-a7a7-f23b89ab36e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------------+\n",
      "|OP_CARRIER_AIRLINE_ID|nb_flights_distinct|\n",
      "+---------------------+-------------------+\n",
      "|19393                |4946               |\n",
      "|19790                |2100               |\n",
      "|19805                |2056               |\n",
      "|20366                |1961               |\n",
      "|20437                |1750               |\n",
      "|20398                |1703               |\n",
      "|20355                |1671               |\n",
      "|20304                |1664               |\n",
      "|19977                |1580               |\n",
      "|20409                |1028               |\n",
      "|20436                |649                |\n",
      "|19930                |618                |\n",
      "|20378                |434                |\n",
      "|19690                |318                |\n",
      "|21171                |254                |\n",
      "+---------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "flightsDF\n",
    "  .groupBy(\"OP_CARRIER_AIRLINE_ID\")\n",
    "  .agg(countDistinct(\"OP_CARRIER_FL_NUM\").as(\"nb_flights_distinct\"))\n",
    "  .orderBy(desc(\"nb_flights_distinct\"))\n",
    "  .show(50, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60efc0b9-b06a-45d9-ba5d-ce6aa45b93a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----------------+-------+\n",
      "|OP_CARRIER_AIRLINE_ID|OP_CARRIER_FL_NUM|nb_vols|\n",
      "+---------------------+-----------------+-------+\n",
      "|19930                |64               |1820   |\n",
      "|19930                |65               |1815   |\n",
      "|19930                |62               |1809   |\n",
      "|19393                |24               |1580   |\n",
      "|19930                |55               |1456   |\n",
      "|19930                |61               |1448   |\n",
      "|19930                |66               |1448   |\n",
      "|19930                |67               |1416   |\n",
      "|19393                |429              |1351   |\n",
      "|19393                |47               |1327   |\n",
      "|19393                |6                |1284   |\n",
      "|19393                |1015             |1281   |\n",
      "|19393                |910              |1251   |\n",
      "|19393                |40               |1206   |\n",
      "|19393                |1983             |1199   |\n",
      "|19393                |132              |1152   |\n",
      "|19393                |38               |1151   |\n",
      "|19393                |1814             |1150   |\n",
      "|19393                |19               |1145   |\n",
      "|19393                |313              |1143   |\n",
      "|19393                |32               |1140   |\n",
      "|19393                |483              |1140   |\n",
      "|19393                |339              |1125   |\n",
      "|19393                |36               |1122   |\n",
      "|19393                |23               |1112   |\n",
      "|19393                |709              |1107   |\n",
      "|19393                |33               |1104   |\n",
      "|19393                |20               |1103   |\n",
      "|19393                |25               |1100   |\n",
      "|19393                |31               |1095   |\n",
      "|19393                |16               |1084   |\n",
      "|19930                |152              |1078   |\n",
      "|19930                |151              |1072   |\n",
      "|19930                |153              |1072   |\n",
      "|20355                |90               |1070   |\n",
      "|20355                |5                |1065   |\n",
      "|19393                |384              |1062   |\n",
      "|19393                |43               |1056   |\n",
      "|19393                |327              |1041   |\n",
      "|19393                |584              |1029   |\n",
      "|19393                |1628             |1028   |\n",
      "|19393                |55               |1024   |\n",
      "|19393                |5                |998    |\n",
      "|19393                |503              |993    |\n",
      "|19393                |3814             |992    |\n",
      "|19393                |45               |989    |\n",
      "|19393                |266              |986    |\n",
      "|19393                |51               |980    |\n",
      "|19393                |168              |965    |\n",
      "|19393                |1703             |964    |\n",
      "+---------------------+-----------------+-------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "flightsDF\n",
    "  .groupBy(\"OP_CARRIER_AIRLINE_ID\", \"OP_CARRIER_FL_NUM\")\n",
    "  .agg(count(\"*\").as(\"nb_vols\"))\n",
    "  .orderBy(desc(\"nb_vols\"))\n",
    "  .show(50, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e583d9c-b1a8-48ee-a794-0cb156fc2b33",
   "metadata": {},
   "source": [
    "## 2. ORIGIN_AIRPORT_ID et DEST_AIRPORT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ff06385-2e7e-484e-adee-bb8395cdd32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightsDF.select(\"ORIGIN_AIRPORT_ID\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fde4392b-1c3f-4126-8344-bf5d7708e888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightsDF.select(\"DEST_AIRPORT_ID\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c3bb39c-5031-4580-962c-4fb9fc58ab07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+\n",
      "|ORIGIN_AIRPORT_ID|nb_flights_distinct|\n",
      "+-----------------+-------------------+\n",
      "|11292            |4487               |\n",
      "|12889            |3928               |\n",
      "|12892            |3759               |\n",
      "|14107            |3623               |\n",
      "|10821            |3532               |\n",
      "|13232            |3504               |\n",
      "|10397            |3480               |\n",
      "|13930            |3470               |\n",
      "|14771            |2941               |\n",
      "|13204            |2789               |\n",
      "|14679            |2773               |\n",
      "|15016            |2756               |\n",
      "|13198            |2697               |\n",
      "|10693            |2681               |\n",
      "|11618            |2527               |\n",
      "|12191            |2513               |\n",
      "|11259            |2500               |\n",
      "|12266            |2482               |\n",
      "|11433            |2467               |\n",
      "|11298            |2433               |\n",
      "+-----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "flightsDF\n",
    "  .groupBy(\"ORIGIN_AIRPORT_ID\")\n",
    "  .agg(countDistinct(\"OP_CARRIER_FL_NUM\").as(\"nb_flights_distinct\"))\n",
    "  .orderBy(desc(\"nb_flights_distinct\"))\n",
    "  .show(20, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40cc64c4-d935-4170-a79b-160518942377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+\n",
      "|DEST_AIRPORT_ID|nb_flights_distinct|\n",
      "+---------------+-------------------+\n",
      "|11292          |4465               |\n",
      "|12889          |3838               |\n",
      "|12892          |3767               |\n",
      "|14107          |3567               |\n",
      "|13232          |3526               |\n",
      "|10821          |3503               |\n",
      "|13930          |3461               |\n",
      "|10397          |3411               |\n",
      "|14771          |2920               |\n",
      "|13204          |2755               |\n",
      "|15016          |2693               |\n",
      "|14679          |2630               |\n",
      "|13198          |2546               |\n",
      "|12191          |2529               |\n",
      "|10693          |2516               |\n",
      "|11618          |2506               |\n",
      "|11259          |2467               |\n",
      "|12266          |2398               |\n",
      "|11298          |2387               |\n",
      "|11433          |2349               |\n",
      "+---------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "flightsDF\n",
    "  .groupBy(\"DEST_AIRPORT_ID\")\n",
    "  .agg(countDistinct(\"OP_CARRIER_FL_NUM\").as(\"nb_flights_distinct\"))\n",
    "  .orderBy(desc(\"nb_flights_distinct\"))\n",
    "  .show(20, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b107807b-1ea0-4004-baff-0f2b2f26315a",
   "metadata": {},
   "source": [
    "## 3. CRS_ELAPSED_TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d279194a-1f9e-4567-91bd-fc68c5b71c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightsDF.select(\"CRS_ELAPSED_TIME\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0caf8d6-b8df-4e0c-959e-05a4d47b7dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|CRS_ELAPSED_TIME|\n",
      "+----------------+\n",
      "|           305.0|\n",
      "|           299.0|\n",
      "|           170.0|\n",
      "|           184.0|\n",
      "|           147.0|\n",
      "|           160.0|\n",
      "|           169.0|\n",
      "|            70.0|\n",
      "|            67.0|\n",
      "|           379.0|\n",
      "|           311.0|\n",
      "|           168.0|\n",
      "|           206.0|\n",
      "|            69.0|\n",
      "|           389.0|\n",
      "|           390.0|\n",
      "|           365.0|\n",
      "|           249.0|\n",
      "|           142.0|\n",
      "|           191.0|\n",
      "+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsDF.select(\"CRS_ELAPSED_TIME\").distinct().show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "371fa223-eb37-4262-b1bc-727e727f70f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary| CRS_ELAPSED_TIME|\n",
      "+-------+-----------------+\n",
      "|  count|          6096761|\n",
      "|    min|              1.0|\n",
      "|    25%|             81.0|\n",
      "|    50%|            115.0|\n",
      "|    75%|            165.0|\n",
      "|    max|           1865.0|\n",
      "|   mean|133.9327569179766|\n",
      "| stddev|72.77188749215703|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsDF\n",
    "  .select(\"CRS_ELAPSED_TIME\")\n",
    "  .summary(\"count\", \"min\", \"25%\", \"50%\", \"75%\", \"max\", \"mean\", \"stddev\")\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc58643b-726e-4a2d-bd29-ba121ba8d926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bornes acceptées : -45.0 à 291.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "quantiles = Array(81.0, 165.0)\n",
       "q1 = 81.0\n",
       "q3 = 165.0\n",
       "iqr = 84.0\n",
       "lowerBound = -45.0\n",
       "upperBound = 291.0\n",
       "flightsNoOutliers = [FL_DATE: date, OP_CARRIER_AIRLINE_ID: int ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[FL_DATE: date, OP_CARRIER_AIRLINE_ID: int ... 10 more fields]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "// Récupérer les quantiles\n",
    "val quantiles = flightsDF.stat.approxQuantile(\"CRS_ELAPSED_TIME\", Array(0.25, 0.75), 0.0)\n",
    "val q1 = quantiles(0)\n",
    "val q3 = quantiles(1)\n",
    "val iqr = q3 - q1\n",
    "\n",
    "val lowerBound = q1 - 1.5 * iqr\n",
    "val upperBound = q3 + 1.5 * iqr\n",
    "\n",
    "println(s\"Bornes acceptées : $lowerBound à $upperBound\")\n",
    "\n",
    "// Filtrer les données\n",
    "val flightsNoOutliers = flightsDF.filter(\n",
    "  col(\"CRS_ELAPSED_TIME\") >= lowerBound && col(\"CRS_ELAPSED_TIME\") <= upperBound\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ed8a68-f212-4610-aa85-3c1aa719bc96",
   "metadata": {},
   "source": [
    "# Null Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7202039c-5cd0-40ef-8a29-ae77d8c40f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------+-----------+\n",
      "|Colonne              |Valeurs_nulles|Pourcentage|\n",
      "+---------------------+--------------+-----------+\n",
      "|FL_DATE              |0             |0.00%      |\n",
      "|OP_CARRIER_AIRLINE_ID|0             |0.00%      |\n",
      "|OP_CARRIER_FL_NUM    |0             |0.00%      |\n",
      "|ORIGIN_AIRPORT_ID    |0             |0.00%      |\n",
      "|DEST_AIRPORT_ID      |0             |0.00%      |\n",
      "|CRS_DEP_TIME         |1             |0.00%      |\n",
      "|ARR_DELAY_NEW        |342986        |1.88%      |\n",
      "|CANCELLED            |18286055      |100.00%    |\n",
      "|DIVERTED             |18286055      |100.00%    |\n",
      "|CRS_ELAPSED_TIME     |12            |0.00%      |\n",
      "|WEATHER_DELAY        |14761092      |80.72%     |\n",
      "|NAS_DELAY            |14761092      |80.72%     |\n",
      "+---------------------+--------------+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "totalCount = 18286055\n",
       "nullCountsExprs = Array(sum(CASE WHEN (FL_DATE IS NULL) THEN 1 ELSE 0 END) AS FL_DATE, sum(CASE WHEN (OP_CARRIER_AIRLINE_ID IS NULL) THEN 1 ELSE 0 END) AS OP_CARRIER_AIRLINE_ID, sum(CASE WHEN (OP_CARRIER_FL_NUM IS NULL) THEN 1 ELSE 0 END) AS OP_CARRIER_FL_NUM, sum(CASE WHEN (ORIGIN_AIRPORT_ID IS NULL) THEN 1 ELSE 0 END) AS ORIGIN_AIRPORT_ID, sum(CASE WHEN (DEST_AIRPORT_ID IS NULL) THEN 1 ELSE 0 END) AS DEST_AIRPORT_ID, sum(CASE WHEN (CRS_DEP_TIME IS NULL) THEN 1 ELSE 0 END) AS CRS_DEP_TIME, sum(CASE WHEN (ARR_DELAY_NEW IS NULL) THEN 1 ELSE 0 END) AS ARR_DELAY_NEW, sum(CASE WHEN (CANCELLED IS NULL) THEN 1 ELSE 0 END) AS CANCELLED, sum(CASE WHEN (DIVERTED IS NULL) THEN 1 ELSE 0 END) AS ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Array(sum(CASE WHEN (FL_DATE IS NULL) THEN 1 ELSE 0 END) AS FL_DATE, sum(CASE WHEN (OP_CARRIER_AIRLINE_ID IS NULL) THEN 1 ELSE 0 END) AS OP_CARRIER_AIRLINE_ID, sum(CASE WHEN (OP_CARRIER_FL_NUM IS NULL) THEN 1 ELSE 0 END) AS OP_CARRIER_FL_NUM, sum(CASE WHEN (ORIGIN_AIRPORT_ID IS NULL) THEN 1 ELSE 0 END) AS ORIGIN_AIRPORT_ID, sum(CASE WHEN (DEST_AIRPORT_ID IS NULL) THEN 1 ELSE 0 END) AS DEST_AIRPORT_ID, sum(CASE WHEN (CRS_DEP_TIME IS NULL) THEN 1 ELSE 0 END) AS CRS_DEP_TIME, sum(CASE WHEN (ARR_DELAY_NEW IS NULL) THEN 1 ELSE 0 END) AS ARR_DELAY_NEW, sum(CASE WHEN (CANCELLED IS NULL) THEN 1 ELSE 0 END) AS CANCELLED, sum(CASE WHEN (DIVERTED IS NULL) THEN 1 ELSE 0 END) AS ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val totalCount = flightsDF.count()\n",
    "\n",
    "val nullCountsExprs = flightsDF.columns.map(c => sum(when(col(c).isNull, 1).otherwise(0)).alias(c))\n",
    "\n",
    "val nullCountsRow = flightsDF.agg(nullCountsExprs.head, nullCountsExprs.tail: _*).first()\n",
    "\n",
    "val nullStats = flightsDF.columns.map { c =>\n",
    "  val nullCount = nullCountsRow.getAs[Long](c)\n",
    "  val percent = (nullCount.toDouble / totalCount) * 100\n",
    "  (c, nullCount, f\"$percent%.2f%%\")\n",
    "}\n",
    "\n",
    "import spark.implicits._\n",
    "val nullStatsDF = nullStats.toSeq.toDF(\"Colonne\", \"Valeurs_nulles\", \"Pourcentage\")\n",
    "\n",
    "nullStatsDF.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2772e8a1-4a6c-4e18-bce3-b32cb4f4f6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------+-----------+\n",
      "|Colonne              |Valeurs_nulles|Pourcentage|\n",
      "+---------------------+--------------+-----------+\n",
      "|FL_DATE              |0             |0.00%      |\n",
      "|OP_CARRIER_AIRLINE_ID|0             |0.00%      |\n",
      "|OP_CARRIER_FL_NUM    |0             |0.00%      |\n",
      "|ORIGIN_AIRPORT_ID    |0             |0.00%      |\n",
      "|DEST_AIRPORT_ID      |0             |0.00%      |\n",
      "|CRS_DEP_TIME         |1             |0.00%      |\n",
      "|ARR_DELAY_NEW        |342986        |1.88%      |\n",
      "|CANCELLED            |18286055      |100.00%    |\n",
      "|DIVERTED             |18286055      |100.00%    |\n",
      "|CRS_ELAPSED_TIME     |12            |0.00%      |\n",
      "|WEATHER_DELAY        |14761092      |80.72%     |\n",
      "|NAS_DELAY            |14761092      |80.72%     |\n",
      "+---------------------+--------------+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "totalCount = 18286055\n",
       "nullCountsExprs = Array(sum(CASE WHEN (FL_DATE IS NULL) THEN 1 ELSE 0 END) AS FL_DATE, sum(CASE WHEN (OP_CARRIER_AIRLINE_ID IS NULL) THEN 1 ELSE 0 END) AS OP_CARRIER_AIRLINE_ID, sum(CASE WHEN (OP_CARRIER_FL_NUM IS NULL) THEN 1 ELSE 0 END) AS OP_CARRIER_FL_NUM, sum(CASE WHEN (ORIGIN_AIRPORT_ID IS NULL) THEN 1 ELSE 0 END) AS ORIGIN_AIRPORT_ID, sum(CASE WHEN (DEST_AIRPORT_ID IS NULL) THEN 1 ELSE 0 END) AS DEST_AIRPORT_ID, sum(CASE WHEN (CRS_DEP_TIME IS NULL) THEN 1 ELSE 0 END) AS CRS_DEP_TIME, sum(CASE WHEN (ARR_DELAY_NEW IS NULL) THEN 1 ELSE 0 END) AS ARR_DELAY_NEW, sum(CASE WHEN (CANCELLED IS NULL) THEN 1 ELSE 0 END) AS CANCELLED, sum(CASE WHEN (DIVERTED IS NULL) THEN 1 ELSE 0 END) AS ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Array(sum(CASE WHEN (FL_DATE IS NULL) THEN 1 ELSE 0 END) AS FL_DATE, sum(CASE WHEN (OP_CARRIER_AIRLINE_ID IS NULL) THEN 1 ELSE 0 END) AS OP_CARRIER_AIRLINE_ID, sum(CASE WHEN (OP_CARRIER_FL_NUM IS NULL) THEN 1 ELSE 0 END) AS OP_CARRIER_FL_NUM, sum(CASE WHEN (ORIGIN_AIRPORT_ID IS NULL) THEN 1 ELSE 0 END) AS ORIGIN_AIRPORT_ID, sum(CASE WHEN (DEST_AIRPORT_ID IS NULL) THEN 1 ELSE 0 END) AS DEST_AIRPORT_ID, sum(CASE WHEN (CRS_DEP_TIME IS NULL) THEN 1 ELSE 0 END) AS CRS_DEP_TIME, sum(CASE WHEN (ARR_DELAY_NEW IS NULL) THEN 1 ELSE 0 END) AS ARR_DELAY_NEW, sum(CASE WHEN (CANCELLED IS NULL) THEN 1 ELSE 0 END) AS CANCELLED, sum(CASE WHEN (DIVERTED IS NULL) THEN 1 ELSE 0 END) AS ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val totalCount = df.count()\n",
    "\n",
    "val nullCountsExprs = df.columns.map(c => sum(when(col(c).isNull, 1).otherwise(0)).alias(c))\n",
    "\n",
    "val nullCountsRow = df.agg(nullCountsExprs.head, nullCountsExprs.tail: _*).first()\n",
    "\n",
    "val nullStats = df.columns.map { c =>\n",
    "  val nullCount = nullCountsRow.getAs[Long](c)\n",
    "  val percent = (nullCount.toDouble / totalCount) * 100\n",
    "  (c, nullCount, f\"$percent%.2f%%\")\n",
    "}\n",
    "\n",
    "import spark.implicits._\n",
    "val nullStatsDF = nullStats.toSeq.toDF(\"Colonne\", \"Valeurs_nulles\", \"Pourcentage\")\n",
    "\n",
    "nullStatsDF.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9ce3e5-966a-476a-8cc4-b16f6287dc4f",
   "metadata": {},
   "source": [
    "# D1, D2, D3 et D4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9bc71ab-e0f2-47d9-891d-82fed6367e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined object FlightDataSetFilterGenerator\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "import com.flightdelay.data.preprocessing.DataPreprocessor\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.{Column, DataFrame, SparkSession}\n",
    "\n",
    "/**\n",
    " * Génère des colonnes binaires D1, D2_<seuil>, D3, D4 (1 ou 0) selon la logique métier :\n",
    " *\n",
    " * - D1 : vols dont le retard total est imputé *seulement* à WEATHER et/ou NAS\n",
    " *        (ARR_DELAY_NEW ≈ WEATHER_DELAY + NAS_DELAY à epsilon près, et ARR_DELAY_NEW > 0)\n",
    " * - D2_<T> : vols avec WEATHER_DELAY > 0 et NAS_DELAY >= T\n",
    " * - D3 : vols avec WEATHER_DELAY > 0 ou NAS_DELAY > 0\n",
    " * - D4 : tous les vols avec ARR_DELAY_NEW > 0\n",
    " *\n",
    " * Nulls gérés via coalesce(..., 0.0)\n",
    " */\n",
    "object FlightDataSetFilterGenerator {\n",
    "\n",
    "  private val D2_THRESHOLDS_MINUTES: Seq[Int] = Seq(15, 30, 45, 60, 90)\n",
    "  private val EPSILON_EQUALITY_MIN = 0.5\n",
    "\n",
    "  private def nzDouble(colName: String): Column =\n",
    "    coalesce(col(colName).cast(\"double\"), lit(0.0))\n",
    "\n",
    "  private def validateRequiredColumns(df: DataFrame): Unit = {\n",
    "    val required = Seq(\"ARR_DELAY_NEW\", \"WEATHER_DELAY\", \"NAS_DELAY\")\n",
    "    val missing = required.filterNot(df.columns.contains)\n",
    "    require(\n",
    "      missing.isEmpty,\n",
    "      s\"Colonnes manquantes: ${missing.mkString(\", \")} (requis: ${required.mkString(\", \")})\"\n",
    "    )\n",
    "  }\n",
    "\n",
    "  /**\n",
    "   * Ajoute les colonnes D1, D2_<seuil>, D3, D4 en binaire (1 / 0)\n",
    "   */\n",
    "  def withDelayFilters(df: DataFrame, epsilon: Double = EPSILON_EQUALITY_MIN): DataFrame = {\n",
    "    validateRequiredColumns(df)\n",
    "\n",
    "    val arr  = nzDouble(\"ARR_DELAY_NEW\")\n",
    "    val wthr = nzDouble(\"WEATHER_DELAY\")\n",
    "    val nas  = nzDouble(\"NAS_DELAY\")\n",
    "\n",
    "    val d4 = when(arr > 0, 1).otherwise(0)\n",
    "    val d3 = when((wthr > 0) or (nas > 0), 1).otherwise(0)\n",
    "    val d1 = when((arr > 0) && (abs(arr - (wthr + nas)) <= epsilon), 1).otherwise(0)\n",
    "\n",
    "    // Appliquer les colonnes de base\n",
    "    val baseDf = df\n",
    "      .withColumn(\"D4\", d4)\n",
    "      .withColumn(\"D3\", d3)\n",
    "      .withColumn(\"D1\", d1)\n",
    "\n",
    "    // Ajouter D2_<seuil>\n",
    "    val dfWithD2 = D2_THRESHOLDS_MINUTES.foldLeft(baseDf) { (acc, thr) =>\n",
    "      val colName = s\"D2_$thr\"\n",
    "      val d2col = when((wthr > 0) && (nas >= thr), 1).otherwise(0)\n",
    "      acc.withColumn(colName, d2col)\n",
    "    }\n",
    "\n",
    "    dfWithD2\n",
    "  }\n",
    "\n",
    "  /**\n",
    "   * Méthode exécutable pour test (facultative)\n",
    "   */\n",
    "  def run(spark: SparkSession, input: DataFrame): DataFrame = {\n",
    "    val enriched = withDelayFilters(input)\n",
    "\n",
    "    val total = enriched.count()\n",
    "    println(s\"[FlightDataSetFilterGenerator] Total vols: $total\")\n",
    "\n",
    "    val colsToLog = Seq(\"D1\", \"D3\", \"D4\") ++ D2_THRESHOLDS_MINUTES.map(t => s\"D2_$t\")\n",
    "    colsToLog.foreach { c =>\n",
    "      val n = enriched.filter(col(c) === 1).count()\n",
    "      val pct = if (total > 0) (n.toDouble / total * 100) else 0.0\n",
    "      println(f\" - $c%-6s : $n%8d vols (${pct}%.2f%%)\")\n",
    "    }\n",
    "\n",
    "    enriched\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86f9d9e8-62ed-4541-98cd-b17a5e603655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FlightDataSetFilterGenerator] Total vols: 18286055\n",
      " - D1     :   710294 vols (3.88%)\n",
      " - D3     :  2024941 vols (11.07%)\n",
      " - D4     :  7017890 vols (38.38%)\n",
      " - D2_15  :    53900 vols (0.29%)\n",
      " - D2_30  :    26658 vols (0.15%)\n",
      " - D2_45  :    14062 vols (0.08%)\n",
      " - D2_60  :     7797 vols (0.04%)\n",
      " - D2_90  :     2570 vols (0.01%)\n",
      "+----------+---------------------+-----------------+-----------------+---------------+------------+-------------+---------+--------+----------------+-------------+---------+---+---+---+-----+-----+-----+-----+-----+\n",
      "|   FL_DATE|OP_CARRIER_AIRLINE_ID|OP_CARRIER_FL_NUM|ORIGIN_AIRPORT_ID|DEST_AIRPORT_ID|CRS_DEP_TIME|ARR_DELAY_NEW|CANCELLED|DIVERTED|CRS_ELAPSED_TIME|WEATHER_DELAY|NAS_DELAY| D4| D3| D1|D2_15|D2_30|D2_45|D2_60|D2_90|\n",
      "+----------+---------------------+-----------------+-----------------+---------------+------------+-------------+---------+--------+----------------+-------------+---------+---+---+---+-----+-----+-----+-----+-----+\n",
      "|2013-07-01|                20363|             3407|            11433|          13342|        1040|          0.0|     NULL|    NULL|            79.0|         NULL|     NULL|  0|  0|  0|    0|    0|    0|    0|    0|\n",
      "|2013-07-01|                20363|             3409|            11433|          12266|        1227|          0.0|     NULL|    NULL|           175.0|         NULL|     NULL|  0|  0|  0|    0|    0|    0|    0|    0|\n",
      "|2013-07-01|                20363|             3848|            13485|          11433|         900|          2.0|     NULL|    NULL|            77.0|         NULL|     NULL|  1|  0|  0|    0|    0|    0|    0|    0|\n",
      "|2013-07-01|                20363|             3851|            11433|          11066|        1535|          0.0|     NULL|    NULL|            60.0|         NULL|     NULL|  0|  0|  0|    0|    0|    0|    0|    0|\n",
      "|2013-07-01|                20363|             3852|            10627|          13487|         500|          0.0|     NULL|    NULL|            82.0|         NULL|     NULL|  0|  0|  0|    0|    0|    0|    0|    0|\n",
      "|2013-07-01|                20363|             3854|            13198|          11193|         800|          0.0|     NULL|    NULL|           102.0|         NULL|     NULL|  0|  0|  0|    0|    0|    0|    0|    0|\n",
      "|2013-07-01|                20363|             3855|            10792|          11433|        1720|         18.0|     NULL|    NULL|            78.0|          0.0|     12.0|  1|  1|  0|    0|    0|    0|    0|    0|\n",
      "|2013-07-01|                20363|             3855|            11433|          10792|        1541|          7.0|     NULL|    NULL|            73.0|         NULL|     NULL|  1|  0|  0|    0|    0|    0|    0|    0|\n",
      "|2013-07-01|                20363|             3859|            10397|          12264|         830|        113.0|     NULL|    NULL|           114.0|          0.0|     19.0|  1|  1|  0|    0|    0|    0|    0|    0|\n",
      "|2013-07-01|                20363|             3859|            12264|          10397|         600|        112.0|     NULL|    NULL|           106.0|          0.0|      4.0|  1|  1|  0|    0|    0|    0|    0|    0|\n",
      "+----------+---------------------+-----------------+-----------------+---------------+------------+-------------+---------+--------+----------------+-------------+---------+---+---+---+-----+-----+-----+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "extendedFlightsDF = [FL_DATE: date, OP_CARRIER_AIRLINE_ID: int ... 18 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[FL_DATE: date, OP_CARRIER_AIRLINE_ID: int ... 18 more fields]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val extendedFlightsDF = FlightDataSetFilterGenerator.run(spark, flightsDF)\n",
    "\n",
    "df2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b6b73c0-c75f-406c-ab0b-72968f78bedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined object DelayBalancedDatasetBuilder\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.{DataFrame, SparkSession, Column}\n",
    "\n",
    "/**\n",
    " * Construit un train/test équilibré (50/50 delayed vs on-time) en filtrant d'abord sur une colonne Dx (=1).\n",
    " *\n",
    " * Procédure :\n",
    " * 1) Filtre df sur dxCol == 1 (optionnellement désactivable).\n",
    " * 2) Construit la label col \"is_delayed\" = (ARR_DELAY_NEW >= delayThresholdMin).\n",
    " * 3) Sépare delayed / on-time.\n",
    " * 4) Split delayed en train/test avec ratio 3:1.\n",
    " * 5) Échantillonne aléatoirement (sans répétition) on-time pour avoir le même nombre que delayed dans train et test.\n",
    " * 6) Renvoie (trainDF, testDF), mélangés.\n",
    " */\n",
    "object DelayBalancedDatasetBuilder {\n",
    "\n",
    "  /** Sélectionne N lignes aléatoires sans répétition. Si N > count(df), prend tout. */\n",
    "  private def sampleN(df: DataFrame, n: Long, seed: Long): DataFrame = {\n",
    "    val total = df.count()\n",
    "    val take = math.min(n, total)\n",
    "    if (take <= 0) df.limit(0)\n",
    "    else df.withColumn(\"__rnd\", rand(seed)).orderBy(col(\"__rnd\")).limit(take.toInt).drop(\"__rnd\")\n",
    "  }\n",
    "\n",
    "  /** Vérifie les colonnes nécessaires. */\n",
    "  private def validate(df: DataFrame, dxCol: String): Unit = {\n",
    "    val needed = Seq(\"ARR_DELAY_NEW\", dxCol)\n",
    "    val missing = needed.filterNot(df.columns.contains)\n",
    "    require(missing.isEmpty, s\"Colonnes manquantes: ${missing.mkString(\", \")}\")\n",
    "  }\n",
    "\n",
    "  /**\n",
    "   * @param df                DataFrame d’origine (doit contenir ARR_DELAY_NEW et dxCol)\n",
    "   * @param dxCol             Colonne binaire 1/0 (ex: \"D1\", \"D2_60\", \"D3\", \"D4\")\n",
    "   * @param delayThresholdMin Seuil pour définir \"delayed\" (ex: 15, 60)\n",
    "   * @param filterOnDxEquals1 Si true, on restreint aux lignes où dxCol == 1 avant équilibrage\n",
    "   * @param trainRatio        Part de delayed envoyée en train (ex: 0.75 ~ 3:1)\n",
    "   * @param seed              Graine de random\n",
    "   * @return (trainBalanced, testBalanced)\n",
    "   */\n",
    "  def buildBalancedTrainTest(\n",
    "      df: DataFrame,\n",
    "      dxCol: String,\n",
    "      delayThresholdMin: Int,\n",
    "      filterOnDxEquals1: Boolean = true,\n",
    "      trainRatio: Double = 0.75,\n",
    "      seed: Long = 42L\n",
    "  ): (DataFrame, DataFrame) = {\n",
    "\n",
    "    validate(df, dxCol)\n",
    "\n",
    "    val base = if (filterOnDxEquals1) df.filter(col(dxCol) === 1) else df\n",
    "\n",
    "    // Label binaire : 1 si retard >= seuil, 0 sinon\n",
    "    val labeled = base.withColumn(\n",
    "      \"is_delayed\",\n",
    "      when(coalesce(col(\"ARR_DELAY_NEW\").cast(\"double\"), lit(0.0)) >= delayThresholdMin, 1).otherwise(0)\n",
    "    )\n",
    "\n",
    "    val delayed   = labeled.filter(col(\"is_delayed\") === 1)\n",
    "    val onTime    = labeled.filter(col(\"is_delayed\") === 0)\n",
    "\n",
    "    // Split des \"delayed\" en 3:1 (train:test)\n",
    "    val Array(trainDelayed, testDelayed) = delayed.randomSplit(Array(trainRatio, 1.0 - trainRatio), seed)\n",
    "\n",
    "    val nTrainDelayed = trainDelayed.count()\n",
    "    val nTestDelayed  = testDelayed.count()\n",
    "\n",
    "    // Sous-échantillonnage on-time pour égaliser\n",
    "    val trainOnTime = sampleN(onTime, nTrainDelayed, seed + 1)\n",
    "    val testOnTime  = sampleN(onTime.except(trainOnTime), nTestDelayed, seed + 2)\n",
    "\n",
    "    // Union + shuffle\n",
    "    val trainBalanced = trainDelayed.unionByName(trainOnTime).withColumn(\"__rnd\", rand(seed + 3)).orderBy(col(\"__rnd\")).drop(\"__rnd\")\n",
    "    val testBalanced  = testDelayed.unionByName(testOnTime).withColumn(\"__rnd\", rand(seed + 4)).orderBy(col(\"__rnd\")).drop(\"__rnd\")\n",
    "\n",
    "    // (Optionnel) Log rapide\n",
    "    def logSplit(name: String, d: DataFrame): Unit = {\n",
    "      val total = d.count()\n",
    "      val nDel  = d.filter(col(\"is_delayed\") === 1).count()\n",
    "      val nOn   = d.filter(col(\"is_delayed\") === 0).count()\n",
    "      println(f\"[$name] total=$total%8d | delayed=$nDel%8d | on-time=$nOn%8d\")\n",
    "    }\n",
    "    logSplit(s\"TRAIN ($dxCol, t=$delayThresholdMin)\", trainBalanced)\n",
    "    logSplit(s\"TEST  ($dxCol, t=$delayThresholdMin)\", testBalanced)\n",
    "\n",
    "    (trainBalanced, testBalanced)\n",
    "  }\n",
    "\n",
    "  /** Variante simple : renvoie un unique DataFrame équilibré (sans split train/test). */\n",
    "  def buildBalancedSingle(\n",
    "      df: DataFrame,\n",
    "      dxCol: String,\n",
    "      delayThresholdMin: Int,\n",
    "      filterOnDxEquals1: Boolean = true,\n",
    "      seed: Long = 42L\n",
    "  ): DataFrame = {\n",
    "    validate(df, dxCol)\n",
    "    val base = if (filterOnDxEquals1) df.filter(col(dxCol) === 1) else df\n",
    "    val labeled = base.withColumn(\n",
    "      \"is_delayed\",\n",
    "      when(coalesce(col(\"ARR_DELAY_NEW\").cast(\"double\"), lit(0.0)) >= delayThresholdMin, 1).otherwise(0)\n",
    "    )\n",
    "    val delayed = labeled.filter(col(\"is_delayed\") === 1)\n",
    "    val onTime  = labeled.filter(col(\"is_delayed\") === 0)\n",
    "    val n = math.min(delayed.count(), onTime.count())\n",
    "    val delayedS = sampleN(delayed, n, seed)\n",
    "    val onTimeS  = sampleN(onTime, n, seed + 1)\n",
    "    delayedS.unionByName(onTimeS).withColumn(\"__rnd\", rand(seed + 2)).orderBy(col(\"__rnd\")).drop(\"__rnd\")\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf2a5e24-6ced-49b4-87e2-156d9d0e81b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN (D2_60, t=60)] total=    5859 | delayed=    5859 | on-time=       0\n",
      "[TEST  (D2_60, t=60)] total=    1938 | delayed=    1938 | on-time=       0\n",
      "+----------+-----+\n",
      "|is_delayed|count|\n",
      "+----------+-----+\n",
      "|         1| 5859|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|is_delayed|count|\n",
      "+----------+-----+\n",
      "|         1| 1938|\n",
      "+----------+-----+\n",
      "\n",
      "+----------+---------------------+-----------------+-----------------+---------------+------------+-------------+---------+--------+----------------+-------------+---------+---+---+---+-----+-----+-----+-----+-----+----------+\n",
      "|   FL_DATE|OP_CARRIER_AIRLINE_ID|OP_CARRIER_FL_NUM|ORIGIN_AIRPORT_ID|DEST_AIRPORT_ID|CRS_DEP_TIME|ARR_DELAY_NEW|CANCELLED|DIVERTED|CRS_ELAPSED_TIME|WEATHER_DELAY|NAS_DELAY| D4| D3| D1|D2_15|D2_30|D2_45|D2_60|D2_90|is_delayed|\n",
      "+----------+---------------------+-----------------+-----------------+---------------+------------+-------------+---------+--------+----------------+-------------+---------+---+---+---+-----+-----+-----+-----+-----+----------+\n",
      "|2014-03-02|                19805|              370|            11298|          14100|        1400|         76.0|     NULL|    NULL|           185.0|         15.0|     61.0|  1|  1|  1|    1|    1|    1|    1|    0|         1|\n",
      "|2012-05-16|                21171|              935|            12892|          14771|         910|        127.0|     NULL|    NULL|            80.0|         19.0|    108.0|  1|  1|  1|    1|    1|    1|    1|    1|         1|\n",
      "|2013-08-07|                20355|             2076|            10397|          14100|        1045|        101.0|     NULL|    NULL|           126.0|          4.0|     97.0|  1|  1|  1|    1|    1|    1|    1|    1|         1|\n",
      "|2012-07-20|                19805|              436|            11298|          11697|        1635|        149.0|     NULL|    NULL|           160.0|          9.0|    133.0|  1|  1|  0|    1|    1|    1|    1|    1|         1|\n",
      "|2012-01-26|                21171|               25|            12478|          14771|        1155|        123.0|     NULL|    NULL|           405.0|          5.0|    118.0|  1|  1|  1|    1|    1|    1|    1|    1|         1|\n",
      "+----------+---------------------+-----------------+-----------------+---------------+------------+-------------+---------+--------+----------------+-------------+---------+---+---+---+-----+-----+-----+-----+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+---------------------+-----------------+-----------------+---------------+------------+-------------+---------+--------+----------------+-------------+---------+---+---+---+-----+-----+-----+-----+-----+----------+\n",
      "|   FL_DATE|OP_CARRIER_AIRLINE_ID|OP_CARRIER_FL_NUM|ORIGIN_AIRPORT_ID|DEST_AIRPORT_ID|CRS_DEP_TIME|ARR_DELAY_NEW|CANCELLED|DIVERTED|CRS_ELAPSED_TIME|WEATHER_DELAY|NAS_DELAY| D4| D3| D1|D2_15|D2_30|D2_45|D2_60|D2_90|is_delayed|\n",
      "+----------+---------------------+-----------------+-----------------+---------------+------------+-------------+---------+--------+----------------+-------------+---------+---+---+---+-----+-----+-----+-----+-----+----------+\n",
      "|2014-08-25|                19977|             1447|            13930|          10721|        1124|        222.0|     NULL|    NULL|           137.0|        141.0|     60.0|  1|  1|  0|    1|    1|    1|    1|    0|         1|\n",
      "|2014-06-09|                19977|             1011|            12266|          14908|        1144|        182.0|     NULL|    NULL|           207.0|         43.0|    139.0|  1|  1|  1|    1|    1|    1|    1|    1|         1|\n",
      "|2013-07-21|                19393|             2683|            10821|          12391|        1715|        116.0|     NULL|    NULL|            60.0|         19.0|     89.0|  1|  1|  0|    1|    1|    1|    1|    0|         1|\n",
      "|2012-01-20|                20304|             5366|            13930|          13198|        1759|        231.0|     NULL|    NULL|            91.0|         19.0|     74.0|  1|  1|  0|    1|    1|    1|    1|    0|         1|\n",
      "|2014-02-09|                20355|              851|            14100|          11292|        1825|        246.0|     NULL|    NULL|           267.0|        142.0|    104.0|  1|  1|  1|    1|    1|    1|    1|    1|         1|\n",
      "+----------+---------------------+-----------------+-----------------+---------------+------------+-------------+---------+--------+----------------+-------------+---------+---+---+---+-----+-----+-----+-----+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trainDF = [FL_DATE: date, OP_CARRIER_AIRLINE_ID: int ... 19 more fields]\n",
       "testDF = [FL_DATE: date, OP_CARRIER_AIRLINE_ID: int ... 19 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[FL_DATE: date, OP_CARRIER_AIRLINE_ID: int ... 19 more fields]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Exemple : équilibrer sur D2_60, seuil \"delayed\" = 60 minutes\n",
    "val (trainDF, testDF) =\n",
    "  DelayBalancedDatasetBuilder.buildBalancedTrainTest(\n",
    "    df = extendedFlightsDF,\n",
    "    dxCol = \"D2_60\",\n",
    "    delayThresholdMin = 60, // ou 15, 30, 45, 90\n",
    "    filterOnDxEquals1 = true, // garde seulement les vols du groupe Dx\n",
    "    trainRatio = 0.75,\n",
    "    seed = 2025L\n",
    "  )\n",
    "\n",
    "// Vérif rapide\n",
    "trainDF.groupBy(\"is_delayed\").count().show()\n",
    "testDF.groupBy(\"is_delayed\").count().show()\n",
    "\n",
    "// Vérif rapide\n",
    "trainDF.show(5)\n",
    "testDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3107255-4bcf-40e6-bee8-c2d714c4061d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdde0ab2-f670-479f-8610-6ed3af223c98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apache_toree_scala - Scala",
   "language": "scala",
   "name": "apache_toree_scala_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
