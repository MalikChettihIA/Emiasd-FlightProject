{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b115457-3161-4df6-8651-1fdce7d6b947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weather = [WBAN: string, WDATE: date ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[WBAN: string, WDATE: date ... 3 more fields]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import java.sql.Date\n",
    "\n",
    "val weather = Seq(\n",
    "  // --- Données du 10 janvier ---\n",
    "  (\"12345\", Date.valueOf(\"2024-01-10\"), 0,     5.0, 1.0),   // 00h00\n",
    "  (\"12345\", Date.valueOf(\"2024-01-10\"), 300,   6.0, 2.0),   // 03h00\n",
    "  (\"12345\", Date.valueOf(\"2024-01-10\"), 2300,  7.0, 3.0),   // 23h00\n",
    "\n",
    "  // --- Données du 11 janvier ---\n",
    "  (\"12345\", Date.valueOf(\"2024-01-11\"), 0,     8.0, 4.0),   // 00h00\n",
    "  (\"12345\", Date.valueOf(\"2024-01-11\"), 1200,  9.0, 5.0)    // 12h00\n",
    ").toDF(\"WBAN\", \"WDATE\", \"WTIME_HHMM\", \"TEMP\", \"WIND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3369b29d-c47a-453f-baac-3a468188cfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------+----+----+\n",
      "| WBAN|     WDATE|WTIME_HHMM|TEMP|WIND|\n",
      "+-----+----------+----------+----+----+\n",
      "|12345|2024-01-10|         0| 5.0| 1.0|\n",
      "|12345|2024-01-10|       300| 6.0| 2.0|\n",
      "|12345|2024-01-10|      2300| 7.0| 3.0|\n",
      "|12345|2024-01-11|         0| 8.0| 4.0|\n",
      "|12345|2024-01-11|      1200| 9.0| 5.0|\n",
      "+-----+----------+----------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "056a156a-33b6-47bd-beee-69ab60c35dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weatherWithRelatievHours = [WBAN: string, WDATE: date ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "hhmmHourCol: (c: org.apache.spark.sql.Column)org.apache.spark.sql.Column\n",
       "buildWeatherWithRelativeHour: (weather: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------+----+----+----+----------+-------+\n",
      "| WBAN|     WDATE|WTIME_HHMM|TEMP|WIND|hour|      DATE|relHour|\n",
      "+-----+----------+----------+----+----+----+----------+-------+\n",
      "|12345|2024-01-10|         0| 5.0| 1.0|   0|2024-01-10|      0|\n",
      "|12345|2024-01-10|       300| 6.0| 2.0|   3|2024-01-10|      3|\n",
      "|12345|2024-01-10|      2300| 7.0| 3.0|  23|2024-01-10|     23|\n",
      "|12345|2024-01-11|         0| 8.0| 4.0|   0|2024-01-11|      0|\n",
      "|12345|2024-01-11|      1200| 9.0| 5.0|  12|2024-01-11|     12|\n",
      "|12345|2024-01-10|         0| 5.0| 1.0|   0|2024-01-11|    -24|\n",
      "|12345|2024-01-10|       300| 6.0| 2.0|   3|2024-01-11|    -21|\n",
      "|12345|2024-01-10|      2300| 7.0| 3.0|  23|2024-01-11|     -1|\n",
      "|12345|2024-01-11|         0| 8.0| 4.0|   0|2024-01-12|    -24|\n",
      "|12345|2024-01-11|      1200| 9.0| 5.0|  12|2024-01-12|    -12|\n",
      "+-----+----------+----------+----+----+----+----------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[WBAN: string, WDATE: date ... 6 more fields]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.Column\n",
    "\n",
    "def hhmmHourCol(c: Column): Column = {\n",
    "    val s  = regexp_replace(c.cast(\"string\"), \":\", \"\")\n",
    "    val p4 = lpad(s, 4, \"0\")\n",
    "    (substring(p4, 1, 2).cast(\"int\") % 24)\n",
    "}\n",
    "\n",
    "/**\n",
    "  * Prépare les données météo pour la jointure avec les vols.\n",
    "  *\n",
    "  * Idée :\n",
    "  *  - Pour chaque enregistrement météo (WBAN, WDATE, WTIME_HHMM),\n",
    "  *    on crée deux vues :\n",
    "  *      1) météo du jour :      DATE = WDATE,  relHour = hour ∈ [0, 23]\n",
    "  *      2) météo de la veille : DATE = WDATE + 1, relHour = hour - 24 ∈ [-24, -1]\n",
    "  *\n",
    "  *  Ainsi, pour un vol à la date D, on peut récupérer :\n",
    "  *    - la météo du jour D       (relHour >= 0)\n",
    "  *    - la météo de la veille D-1 (relHour < 0)\n",
    "  */\n",
    "def buildWeatherWithRelativeHour(weather: DataFrame): DataFrame = {\n",
    "\n",
    "  // 1) Normalisation de l'heure (WTIME_HHMM → hour ∈ [0, 23])\n",
    "  val weatherWithHour = weather\n",
    "    .withColumn(\"hour\", hhmmHourCol(col(\"WTIME_HHMM\")))\n",
    "    // on élimine les lignes où l'heure est invalide (NULL ou hors [0,23])\n",
    "    .filter(col(\"hour\").between(0, 23))\n",
    "\n",
    "  // 2) Météo du jour même : DATE = WDATE, relHour = hour\n",
    "  val sameDateWeather = weatherWithHour\n",
    "    .withColumn(\"DATE\", col(\"WDATE\"))\n",
    "    .withColumn(\"relHour\", col(\"hour\"))\n",
    "\n",
    "  // 3) Météo de la veille, rattachée au jour suivant :\n",
    "  //    Exemple : WDATE = 10/01 23h → DATE = 11/01, relHour = -1\n",
    "  val previousDayWeatherForNextDate = weatherWithHour\n",
    "    .withColumn(\"DATE\", date_add(col(\"WDATE\"), 1))\n",
    "    .withColumn(\"relHour\", col(\"hour\") - 24)\n",
    "\n",
    "  // 4) Union des deux vues + garde seulement la fenêtre [-24, 23]\n",
    "  val weatherWithRelativeHour = sameDateWeather\n",
    "    .unionByName(previousDayWeatherForNextDate)\n",
    "    .filter(col(\"relHour\").between(-24, 23))\n",
    "\n",
    "  weatherWithRelativeHour\n",
    "}\n",
    "\n",
    "val weatherWithRelatievHours = buildWeatherWithRelativeHour(weather)\n",
    "weatherWithRelatievHours.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2c1d4c-34da-4f81-ab3b-054ea29ce76d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apache_toree_scala - Scala",
   "language": "scala",
   "name": "apache_toree_scala_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
