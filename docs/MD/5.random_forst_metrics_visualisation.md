# Flight Delay Prediction - Metrics Visualization

## Overview

Le pipeline d'entraînement génère automatiquement des fichiers CSV contenant les métriques du modèle. Ces fichiers peuvent être visualisés avec le script Python `visualize_metrics.py`.

## Fichiers Générés

Après l'entraînement, les métriques sont sauvegardées dans :
```
/output/metrics/{model_name}_{model_type}/
├── train_test_comparison.csv      # Comparaison train/test pour chaque métrique
├── confusion_matrix_train.csv      # Matrice de confusion (train)
├── confusion_matrix_test.csv       # Matrice de confusion (test)
└── feature_importance.csv          # Importance des features (Random Forest)
```

Pour notre configuration actuelle :
```
/output/metrics/flight_delay_rf_randomforest/
```

## Structure des Fichiers CSV

### 1. `train_test_comparison.csv`
```csv
metric,train,test,gap
accuracy,0.850000,0.840000,0.010000
precision,0.830000,0.820000,0.010000
recall,0.870000,0.860000,0.010000
f1_score,0.850000,0.840000,0.010000
auc_roc,0.920000,0.910000,0.010000
auc_pr,0.880000,0.870000,0.010000
```

### 2. `confusion_matrix_test.csv`
```csv
,Predicted_Positive,Predicted_Negative
Actual_Positive,12500,1500
Actual_Negative,2000,34000
```

### 3. `feature_importance.csv`
```csv
feature_index,importance
42,0.123456
15,0.098765
89,0.087654
...
```

## Installation des Dépendances Python

```bash
pip install pandas matplotlib seaborn numpy
```

Ou avec conda :
```bash
conda install pandas matplotlib seaborn numpy
```

## Utilisation du Script de Visualisation

### Commande de Base

```bash
python work/scripts/visualize_metrics.py /output/metrics/flight_delay_rf_randomforest
```

### Exemple Complet (depuis la racine du projet)

```bash
# Après l'entraînement du modèle
cd /Users/malikchettih/Projects/Emiasd-Projects/Emiasd-FlightProject

# Générer les visualisations
python work/scripts/visualize_metrics.py /output/metrics/flight_delay_rf_randomforest
```

## Graphiques Générés

Le script génère automatiquement les visualisations suivantes dans le sous-répertoire `plots/` :

### 1. **train_test_comparison.png**
- **Bar Chart** : Comparaison des métriques train vs test
- **Gap Analysis** : Analyse de l'overfitting (différence train-test)
- Seuil d'alerte à 5% de gap

### 2. **confusion_matrices.png**
- Matrices de confusion côte à côte (train et test)
- Heatmap avec annotations des valeurs

### 3. **feature_importance.png**
- Top 30 features les plus importantes
- Bar chart horizontal avec valeurs
- Gradient de couleur selon l'importance

### 4. **metrics_radar.png**
- Radar chart des métriques principales
- Comparaison visuelle train vs test
- Métriques : accuracy, precision, recall, F1, AUC-ROC

### 5. **summary_report.txt**
- Rapport texte résumant les performances
- Analyse de l'overfitting
- Top 10 features les plus importantes

## Structure des Outputs

```
/output/metrics/flight_delay_rf_randomforest/
├── train_test_comparison.csv
├── confusion_matrix_train.csv
├── confusion_matrix_test.csv
├── feature_importance.csv
└── plots/
    ├── train_test_comparison.png
    ├── confusion_matrices.png
    ├── feature_importance.png
    ├── metrics_radar.png
    └── summary_report.txt
```

## Personnalisation

### Modifier le nombre de features affichées

```python
# Dans visualize_metrics.py, ligne ~160
plot_feature_importance(metrics, output_dir, top_n=50)  # Au lieu de 30
```

### Changer les couleurs

```python
# Modifier les couleurs dans les fonctions de plot
colors = ['#your_color_1', '#your_color_2']
```

### Ajouter de nouvelles métriques

1. Modifier `ModelEvaluator.scala` pour calculer la métrique
2. Ajouter la métrique à `saveMetricsToFile()`
3. Modifier `visualize_metrics.py` pour afficher la nouvelle métrique

## Exemple d'Utilisation Complète

```bash
# 1. Entraîner le modèle (génère automatiquement les métriques)
cd work
./run-on-local.sh

# 2. Attendre la fin de l'entraînement

# 3. Générer les visualisations
python scripts/visualize_metrics.py /output/metrics/flight_delay_rf_randomforest

# 4. Consulter les résultats
open /output/metrics/flight_delay_rf_randomforest/plots/
```

## Interprétation des Résultats

### Gap Analysis
- **Gap < 5%** : Modèle bien généralisé ✓
- **Gap 5-10%** : Overfitting modéré ⚠
- **Gap > 10%** : Overfitting significatif ✗

### Feature Importance
- Identifie les features les plus utiles pour la prédiction
- Aide à comprendre quels facteurs influencent les retards
- Peut guider l'ingénierie de features futures

### Confusion Matrix
- **True Positives (TP)** : Retards correctement prédits
- **True Negatives (TN)** : À l'heure correctement prédit
- **False Positives (FP)** : Faux retards (Type I error)
- **False Negatives (FN)** : Retards manqués (Type II error)

## Dépannage

### Erreur : "No metrics files found"
- Vérifier que l'entraînement s'est bien terminé
- Vérifier le chemin du répertoire de métriques
- S'assurer que les fichiers CSV ont bien été générés

### Erreur : "ModuleNotFoundError: No module named 'pandas'"
```bash
pip install pandas matplotlib seaborn numpy
```

### Les graphiques ne s'affichent pas
- Les graphiques sont sauvegardés en PNG, pas affichés à l'écran
- Chercher dans le sous-répertoire `plots/`

## Notes Techniques

- **Format CSV** : Compatible avec Excel, R, Julia, etc.
- **Encodage** : UTF-8
- **Séparateur** : Virgule (`,`)
- **DPI des images** : 300 (haute qualité pour publications)
- **Format des images** : PNG (transparent background)
