# Fix: Empty Training Set avec numFolds: 1

## Erreur RencontrÃ©e

```
java.lang.IllegalArgumentException: DecisionTree requires size of input RDD > 0, but was given by empty one.
```

**Contexte :**
```
[STEP 2] Cross-Validation on Development Set
--------------------------------------------------------------------------------
[CrossValidator] Starting K-Fold Cross-Validation
  - Number of folds: 1
  - Grid Search: ENABLED

[RandomForest] Training with hyperparameters:
  - Number of trees: 100
  - Max depth: 10
  ...

ERROR: DecisionTree requires size of input RDD > 0, but was given by empty one.
```

---

## Cause Racine

La configuration avait `numFolds: 1` :

```yaml
# local-config.yml (INCORRECT)
train:
  trainRatio: 0.8

  crossValidation:
    numFolds: 1  # â† ERREUR!
```

### Pourquoi `numFolds: 1` Cause un Training Set Vide ?

Le K-Fold Cross-Validation divise les donnÃ©es en `k` parties Ã©gales :

**Avec `numFolds: 1` :**
```
Development Set (601,224 samples)
â”œâ”€ Fold 0: 100% des donnÃ©es
â”‚   â”œâ”€ Training: 0%       â† VIDE ! (0 samples)
â”‚   â””â”€ Validation: 100%   â† Toutes les donnÃ©es (601,224 samples)
```

**RÃ©sultat :** Le Random Forest reÃ§oit un training set vide â†’ Erreur !

---

### Explication MathÃ©matique

Pour K-Fold Cross-Validation :
- **Training size** = `(k-1)/k Ã— total`
- **Validation size** = `1/k Ã— total`

**Avec k=1 :**
- Training = `(1-1)/1 Ã— 601,224` = `0 Ã— 601,224` = **0 samples** âŒ
- Validation = `1/1 Ã— 601,224` = **601,224 samples** âœ“

**Avec k=5 (correct) :**
- Training = `(5-1)/5 Ã— 601,224` = `0.8 Ã— 601,224` = **480,979 samples** âœ“
- Validation = `1/5 Ã— 601,224` = `0.2 Ã— 601,224` = **120,245 samples** âœ“

---

## Solution AppliquÃ©e

### Fichier ModifiÃ© : `local-config.yml`

**Avant :**
```yaml
crossValidation:
  numFolds: 1  # â† INCORRECT
```

**AprÃ¨s :**
```yaml
crossValidation:
  numFolds: 5  # â† CORRECT
```

### Valeurs Valides pour `numFolds`

| numFolds | Training % | Validation % | RecommandÃ© ? |
|----------|------------|--------------|--------------|
| 1 | 0% | 100% | âŒ **INVALIDE** (training vide) |
| 2 | 50% | 50% | âš ï¸ Peu de donnÃ©es d'entraÃ®nement |
| 3 | 67% | 33% | âœ… OK (petit dataset) |
| 5 | 80% | 20% | âœ… **STANDARD** (recommandÃ©) |
| 10 | 90% | 10% | âœ… OK (grand dataset) |

**RÃ¨gle :** `numFolds >= 2` obligatoire !

---

## RÃ©sultat Attendu AprÃ¨s Fix

Avec `numFolds: 5`, le pipeline crÃ©era 5 folds :

```
Development Set (601,224 samples)
â”œâ”€ Fold 0:
â”‚   â”œâ”€ Training: 480,979 samples (80%)  â† 4 folds
â”‚   â””â”€ Validation: 120,245 samples (20%) â† 1 fold
â”œâ”€ Fold 1:
â”‚   â”œâ”€ Training: 480,979 samples (80%)
â”‚   â””â”€ Validation: 120,245 samples (20%)
â”œâ”€ Fold 2:
â”‚   â”œâ”€ Training: 480,979 samples (80%)
â”‚   â””â”€ Validation: 120,245 samples (20%)
â”œâ”€ Fold 3:
â”‚   â”œâ”€ Training: 480,979 samples (80%)
â”‚   â””â”€ Validation: 120,245 samples (20%)
â””â”€ Fold 4:
    â”œâ”€ Training: 480,979 samples (80%)
    â””â”€ Validation: 120,245 samples (20%)

Average metrics across 5 folds â†’ Final model
```

**Logs attendus :**
```
[CrossValidator] Starting K-Fold Cross-Validation
  - Number of folds: 5
  - Grid Search: ENABLED

[Fold 1/5] Training...
  - Training samples: 480,979
  - Validation samples: 120,245

[RandomForest] Training completed
  - Training accuracy: 85.23%
  - Validation F1: 62.45%

[Fold 2/5] Training...
...
```

---

## Pourquoi Avait-on `numFolds: 1` ?

### HypothÃ¨ses

1. **Test rapide** : Pour dÃ©sactiver temporairement la cross-validation
2. **Copie d'erreur** : Valeur par dÃ©faut incorrecte
3. **Confusion** : PensÃ©e que 1 fold = pas de split

### Comment DÃ©sactiver la Cross-Validation Correctement ?

Si vous voulez un **simple train/test split** sans cross-validation :

**Option 1 : Utiliser 2 folds (split 50/50)**
```yaml
crossValidation:
  numFolds: 2  # Training 50%, Validation 50%
```

**Option 2 : Augmenter le trainRatio et utiliser 5 folds**
```yaml
train:
  trainRatio: 0.9  # 90% dev, 10% hold-out test

  crossValidation:
    numFolds: 5  # Sur les 90% dev : 72% training, 18% validation par fold
```

**Option 3 : Code custom (non supportÃ© actuellement)**
```scala
// DÃ©sactiver complÃ¨tement le K-Fold
// EntraÃ®ner directement sur trainRatio sans CV
// NÃ©cessite modification du code MLPipeline.scala
```

---

## VÃ©rification du Fix

### 1. VÃ©rifier la Configuration

```bash
grep -A 3 "crossValidation:" src/main/resources/local-config.yml
```

**RÃ©sultat attendu :**
```yaml
crossValidation:
  numFolds: 5
```

### 2. Recompiler

```bash
sbt package
```

### 3. Relancer le Pipeline

```bash
./submit.sh
```

### 4. VÃ©rifier les Logs

**Chercher :**
```bash
grep "Number of folds" logs.txt
```

**RÃ©sultat attendu :**
```
[CrossValidator] Starting K-Fold Cross-Validation
  - Number of folds: 5
```

**Chercher :**
```bash
grep "Training samples:" logs.txt
```

**RÃ©sultat attendu :**
```
[Fold 1/5] Training...
  - Training samples: 480,979
  - Validation samples: 120,245
```

**Si vous voyez encore "Training samples: 0"** â†’ Le JAR n'a pas Ã©tÃ© rÃ©gÃ©nÃ©rÃ© avec la nouvelle config

---

## Autres Erreurs Similaires

### "Expected numFolds > 1"

**Erreur :**
```
java.lang.IllegalArgumentException: requirement failed: numFolds must be > 1
```

**Cause :** Spark valide `numFolds >= 2` Ã  la crÃ©ation du CrossValidator

**Solution :** MÃªme fix que ci-dessus (`numFolds: 5`)

---

### "Training dataset is empty"

**Erreur :**
```
java.lang.IllegalStateException: Training dataset is empty
```

**Causes possibles :**
1. `numFolds: 1` (ce fix)
2. DonnÃ©es filtrÃ©es complÃ¨tement par le preprocessing
3. Tous les records ont des valeurs nulles dans les features

**Diagnostic :**
```scala
// VÃ©rifier le nombre de records avant training
println(s"Training samples: ${trainingData.count()}")
```

---

## RÃ©sumÃ©

| Avant | AprÃ¨s |
|-------|-------|
| âŒ `numFolds: 1` | âœ… `numFolds: 5` |
| âŒ Training set vide (0 samples) | âœ… Training set valide (480,979 samples) |
| âŒ Erreur "empty RDD" | âœ… EntraÃ®nement rÃ©ussi |
| âŒ Pas de cross-validation possible | âœ… Cross-validation sur 5 folds |

**Configuration recommandÃ©e :**
```yaml
train:
  trainRatio: 0.8  # 80% dev, 20% hold-out test

  crossValidation:
    numFolds: 5  # K-Fold CV sur les 80% dev
```

**RÃ©partition finale :**
- **Development (80%)** : 601,224 samples
  - Training (64%) : 480,979 samples (4/5 des dev)
  - Validation (16%) : 120,245 samples (1/5 des dev)
- **Hold-out Test (20%)** : 150,058 samples

---

## Prochaine Ã‰tape

Relancer le pipeline :

```bash
./submit.sh
```

L'entraÃ®nement devrait maintenant fonctionner correctement avec 5 folds de cross-validation ! ğŸ¯
