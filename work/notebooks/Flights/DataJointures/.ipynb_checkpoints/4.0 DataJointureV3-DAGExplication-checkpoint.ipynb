{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e159c5ae-37c7-43b7-a800-6349093ad707",
   "metadata": {},
   "source": [
    "# Data Jointure V4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e54813-1f4c-4ba8-ae6f-bd3f4571fb6a",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b9013a-88ff-4c24-8b38-c69e9114ef2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from file:///home/jovyan/work/apps/Emiasd-Flight-Data-Analysis.jar\n",
      "Finished download of Emiasd-Flight-Data-Analysis.jar\n",
      "Using cached version of Emiasd-Flight-Data-Analysis.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar file:///home/jovyan/work/apps/Emiasd-Flight-Data-Analysis.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee6509b-16ae-49fc-b829-db9aed8c8820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "args = Array(jupyter)\n",
       "configuration = AppConfiguration(local,CommonConfig(42,true,debug,false,false,DataConfig(/home/jovyan/work/data,FileConfig(/home/jovyan/work/data/FLIGHT-3Y/Flights/201201*.csv),FileConfig(/home/jovyan/work/data/FLIGHT-3Y/Weather/20101*.txt),FileConfig(/home/jovyan/work/data/FLIGHT-3Y/wban_airport_timezone.csv)),OutputConfig(/home/jovyan/work/output,FileConfig(/home/jovyan/work/output/data),FileConfig(/home/jovyan/work/output/model),None),MLFlowConfig(false,http://localhost:5555),/scripts),Stream(ExperimentConfig(Experience-local,Ba...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "AppConfiguration(local,CommonConfig(42,true,debug,false,false,DataConfig(/home/jovyan/work/data,FileConfig(/home/jovyan/work/data/FLIGHT-3Y/Flights/201201*.csv),FileConfig(/home/jovyan/work/data/FLIGHT-3Y/Weather/20101*.txt),FileConfig(/home/jovyan/work/data/FLIGHT-3Y/wban_airport_timezone.csv)),OutputConfig(/home/jovyan/work/output,FileConfig(/home/jovyan/work/output/data),FileConfig(/home/jovyan/work/output/model),None),MLFlowConfig(false,http://localhost:5555),/scripts),Stream(ExperimentConfig(Experience-local,Ba..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import com.flightdelay.config.{AppConfiguration, ConfigurationLoader, ExperimentConfig}\n",
    "import com.flightdelay.data.loaders.FlightDataLoader\n",
    "\n",
    "// Env Configuration\n",
    "val args: Array[String] = Array(\"jupyter\")\n",
    "implicit val configuration: AppConfiguration = ConfigurationLoader.loadConfiguration(args)\n",
    "implicit val experimentConfig: ExperimentConfig = configuration.experiments(0)\n",
    "\n",
    "val spark = SparkSession.builder()\n",
    "  .config(sc.getConf)\n",
    "  .config(\"spark.eventLog.enabled\", \"true\")\n",
    "  .config(\"spark.eventLog.dir\", s\"${configuration.common.output.basePath}/spark-events\")  // ex: \"file:/tmp/spark-events\" ou \"hdfs:///spark-events\"\n",
    "  .getOrCreate()\n",
    "\n",
    "// Rendre la session Spark implicite\n",
    "implicit val session = spark\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080dd5ff-6a58-4ec9-bd15-b0d629e468c6",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e96dc104-1631-4d57-8b1a-6b6aeb896805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Flight DF Count: ,3908458)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "flightDFPath = /home/jovyan/work/output/common/data/processed_flights.parquet\n",
       "flightData = [OP_CARRIER_AIRLINE_ID: int, DEST_AIRPORT_ID: int ... 32 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[OP_CARRIER_AIRLINE_ID: int, DEST_AIRPORT_ID: int ... 32 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val flightDFPath = s\"${configuration.common.output.basePath}/common/data/processed_flights.parquet\"\n",
    "val flightData = spark.read.parquet(flightDFPath)\n",
    "\n",
    "println(\"Flight DF Count: \", flightData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cccf286a-46b7-4aaf-881d-048ad866fd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weatherDFPath = /home/jovyan/work/output/common/data/processed_weather.parquet\n",
       "weatherData = [RelativeHumidity: double, feature_visibility_category: string ... 16 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Weather DF Count: ,1549320)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[RelativeHumidity: double, feature_visibility_category: string ... 16 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val weatherDFPath = s\"${configuration.common.output.basePath}/common/data/processed_weather.parquet\"\n",
    "val weatherData = spark.read.parquet(weatherDFPath)\n",
    "\n",
    "println(\"Weather DF Count: \", weatherData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22f7ddc-6864-4a71-9e7e-b373a3217f0b",
   "metadata": {},
   "source": [
    "## Préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef4a1331-95e9-48c1-bbc8-f094cabf4865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weatherOriginDepthHours = 3\n",
       "weatherDestinationDepthHours = 3\n",
       "labeledFlightData = [OP_CARRIER_AIRLINE_ID: int, DEST_AIRPORT_ID: int ... 33 more fields]\n",
       "flightFeaturesWithTarget = Some(Vector(OP_CARRIER_AIRLINE_ID, DEST_AIRPORT_ID, ORIGIN_AIRPORT_ID, feature_departure_hour_rounded_cos, CRS_ELAPSED_TIME, feature_departure_hour_rounded_sin, feature_arrival_time_period, feature_flight_week_of_year_cos, CRS_DEP_TIME, feature_flight_week_of_year_sin, feature_departure_time_period, is_delayed))\n",
       "weatherFeatures = Some(Vector(RelativeHumidity, feature_visibility_c...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 25/12/11 21:06:50   - Automatically adding target 'is_delayed' to flight features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Some(Vector(RelativeHumidity, feature_visibility_c..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import com.flightdelay.features.balancer.DelayBalancedDatasetBuilder\n",
    "import com.flightdelay.utils.DebugUtils._\n",
    "import com.flightdelay.utils.MetricsUtils\n",
    "\n",
    "val weatherOriginDepthHours = experimentConfig.featureExtraction.weatherOriginDepthHours\n",
    "val weatherDestinationDepthHours = experimentConfig.featureExtraction.weatherDestinationDepthHours\n",
    "\n",
    "\n",
    "val labeledFlightData =  DelayBalancedDatasetBuilder.prepareLabeledDataset(\n",
    "  df = flightData,\n",
    "  dxCol = experimentConfig.featureExtraction.dxCol\n",
    ")\n",
    "\n",
    "val flightFeaturesWithTarget = experimentConfig.featureExtraction.flightSelectedFeatures.map { features =>\n",
    "    val featureNames = features.keys.toSeq\n",
    "    if (featureNames.contains(experimentConfig.target)) {\n",
    "      featureNames\n",
    "    } else {\n",
    "      info(s\"  - Automatically adding target '${experimentConfig.target}' to flight features\")\n",
    "      featureNames :+ experimentConfig.target\n",
    "    }\n",
    "}\n",
    "\n",
    "val weatherFeatures = experimentConfig.featureExtraction.weatherSelectedFeatures.map(_.keys.toSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a341a8d-56e2-4b0d-97bb-72819938dae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cores = 14\n",
       "numPartsOrigin = 46\n",
       "numPartsDest = 73\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "pickParts: (mult: Double, minAbs: Int, maxAbs: Int)Int\n",
       "hhmmHourCol: (c: org.apache.spark.sql.Column)org.apache.spark.sql.Column\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// =====================================================================\n",
    "// Flight × Weather en DataFrame (Map → Hash partition → Reduce)\n",
    "// - Fenêtre 12h avant départ (Wo_*) et 12h avant arrivée (Wd_*)\n",
    "// - Gestion veille via relHour (duplication J et J+1)\n",
    "// - Un seul job global avec Metrics.withJob\n",
    "// =====================================================================\n",
    "import org.apache.spark.sql.{DataFrame, Row, Column}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "\n",
    "// ------------------------\n",
    "// Paramètres de partitions \"reducers\"\n",
    "// ------------------------\n",
    "\n",
    "\n",
    "val cores = spark.sparkContext.defaultParallelism\n",
    "def pickParts(mult: Double, minAbs: Int, maxAbs: Int): Int =\n",
    "math.min(maxAbs, math.max(minAbs, math.round(cores * mult).toInt))\n",
    "\n",
    "val numPartsOrigin = pickParts(3.3, 32, 128) // ≈ 40\n",
    "val numPartsDest   = pickParts(5.2, 48, 192) // ≈ 64\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", numPartsDest) // borne haute DF\n",
    "\n",
    "// ------------------------\n",
    "// Utilitaire HHMM -> hour [0..23] (sans UDF) (Map)\n",
    "// ------------------------\n",
    "def hhmmHourCol(c: Column): Column = {\n",
    "  val s  = regexp_replace(c.cast(\"string\"), \":\", \"\")\n",
    "  val p4 = lpad(s, 4, \"0\")\n",
    "  (substring(p4, 1, 2).cast(\"int\") % 24)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f721e751-0437-4679-8142-69cefdb97933",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after ORIGIN join: 3908458, rows after DEST join: 3908458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "flights = [OP_CARRIER_AIRLINE_ID: int, DEST_AIRPORT_ID: int ... 33 more fields]\n",
       "weather = [WDATE: date, WTIME_HHMM: string ... 18 more fields]\n",
       "weatherWithHour = [WDATE: date, WTIME_HHMM: string ... 19 more fields]\n",
       "meteoSameDay = [WDATE: date, WTIME_HHMM: string ... 20 more fields]\n",
       "meteoNextDay = [WDATE: date, WTIME_HHMM: string ... 20 more fields]\n",
       "weatherRel = [WDATE: date, WTIME_HHMM: string ... 20 more fields]\n",
       "staticCols = List(relHour AS hour, WBAN, WDATE, WTIME_HHMM)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "staticNames: scala.collection.immutable.Set[Str...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "List(relHour AS hour, WBAN, WDATE, WTIME_HHMM)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import com.flightdelay.utils.MetricsUtils\n",
    "\n",
    "MetricsUtils.withUiLabels(\n",
    "  groupId = \"NoteBook.FeaturePipeline.join\",\n",
    "  desc    = \"NoteBook.FeaturePipeline.join\",\n",
    "  tags    = \"sampling,split,balance\"\n",
    ") {\n",
    "        \n",
    "    // ------------------------\n",
    "    // Sélection des colonnes utiles (Map)\n",
    "    // ------------------------\n",
    "    //flightDF_filtered\n",
    "    val flights = labeledFlightData\n",
    "    \n",
    "    val weather = weatherData.select(\n",
    "        col(\"Date\").cast(DateType).as(\"WDATE\"),\n",
    "        col(\"Time\").as(\"WTIME_HHMM\"),\n",
    "        col(\"*\")\n",
    "    ).where(col(\"WBAN\").isNotNull && length(col(\"WBAN\")) > 0 && col(\"WDATE\").isNotNull)\n",
    "    \n",
    "    \n",
    "    \n",
    "    // ------------------------\n",
    "    // Préparation météo avec relHour + duplication J/J+1 (Map)\n",
    "    // ------------------------\n",
    "    val weatherWithHour = weather\n",
    "      .withColumn(\"hour\", hhmmHourCol(col(\"WTIME_HHMM\")))\n",
    "      .na.fill(Map(\"hour\" -> -1))\n",
    "    \n",
    "    val meteoSameDay = weatherWithHour\n",
    "      .withColumn(\"relHour\", col(\"hour\"))\n",
    "      .withColumn(\"DATE\", col(\"WDATE\"))\n",
    "    \n",
    "    val meteoNextDay = weatherWithHour\n",
    "      .withColumn(\"relHour\", col(\"hour\") - lit(24))\n",
    "      .withColumn(\"DATE\", date_add(col(\"WDATE\"), 1))\n",
    "    \n",
    "    val weatherRel = meteoSameDay.unionByName(meteoNextDay)\n",
    "      .filter(col(\"relHour\").between(-24, 23))\n",
    "    \n",
    "    // ------------------------\n",
    "    // Reduce météo par clé → Map relHour -> struct (Reduce)\n",
    "    // ------------------------\n",
    "    \n",
    "    // 1) Récupérer les features météo depuis la config (Option[Map[...]])\n",
    "    \n",
    "    \n",
    "    // 2) Colonnes fixes dans la struct\n",
    "    val staticCols = Seq(\n",
    "      col(\"relHour\").as(\"hour\"),\n",
    "      col(\"WBAN\"),\n",
    "      col(\"WDATE\"),\n",
    "      col(\"WTIME_HHMM\")\n",
    "    )\n",
    "    \n",
    "    // 3) Colonnes dynamiques venant de la config\n",
    "    val staticNames = Set(\"relHour\", \"WBAN\", \"WDATE\", \"WTIME_HHMM\")\n",
    "    \n",
    "    val allWeatherCols: Seq[String] =\n",
    "      weatherFeatures.getOrElse(Seq.empty[String])\n",
    "    \n",
    "    val dynamicFeatureCols =\n",
    "      allWeatherCols\n",
    "        .filterNot(staticNames.contains)\n",
    "        .map(c => col(c).alias(c))\n",
    "    \n",
    "    // 4) Struct finale : [hour, WBAN, WDATE, WTIME_HHMM, <features>...]\n",
    "    val weatherStruct =\n",
    "      struct((staticCols ++ dynamicFeatureCols): _*)\n",
    "    \n",
    "    // 5) Agrégation en map relHour -> struct(...)\n",
    "    val weatherByKey: DataFrame =\n",
    "      weatherRel\n",
    "        .groupBy(col(\"WBAN\"), col(\"DATE\"))\n",
    "        .agg(\n",
    "          map_from_entries(\n",
    "            collect_list(struct(col(\"relHour\"), weatherStruct))\n",
    "          ).as(\"wmap\")\n",
    "        )\n",
    "    \n",
    "    // ------------------------\n",
    "    // JOIN #1 — ORIGIN (Partition = hash(ORIGIN_WBAN, UTC_FL_DATE))\n",
    "    // ------------------------\n",
    "    val flightsDep = flights\n",
    "    .withColumn(\"depHour\", coalesce(hhmmHourCol(col(\"UTC_CRS_DEP_TIME\")), lit(0)))\n",
    "    \n",
    "    val originPre = flightsDep\n",
    "    .repartition(numPartsOrigin, col(\"ORIGIN_WBAN\"), col(\"UTC_FL_DATE\")) // <-- Hash partition explicite\n",
    "    .join(\n",
    "      weatherByKey.hint(\"shuffle_hash\"),\n",
    "      col(\"ORIGIN_WBAN\") === weatherByKey(\"WBAN\") &&\n",
    "      col(\"UTC_FL_DATE\")    === weatherByKey(\"DATE\"),\n",
    "      \"left\"\n",
    "    )\n",
    "    .drop(weatherByKey(\"WBAN\")).drop(weatherByKey(\"DATE\"))\n",
    "    \n",
    "    val originWithWoArr = originPre\n",
    "    .withColumn(\"Wo\", expr(\"transform(sequence(1, 3), i -> element_at(wmap, depHour - i))\"))\n",
    "    .drop(\"wmap\")\n",
    "    \n",
    "    val woCols = (0 until 3).map(i => col(\"Wo\").getItem(i).as(s\"Wo_h${i+1}\"))\n",
    "    val originDF = originWithWoArr\n",
    "    .select(col(\"*\") +: woCols: _*)\n",
    "    .drop(\"Wo\")\n",
    "    .persist()\n",
    "    \n",
    "    // ------------------------\n",
    "    // JOIN #2 — DEST (Partition = hash(DEST_WBAN, UTC_ARR_DATE))\n",
    "    // ------------------------\n",
    "    val flightsArr = originDF\n",
    "    .withColumn(\"arrHour\", coalesce(hhmmHourCol(col(\"UTC_ARR_TIME\")), lit(0)))\n",
    "    \n",
    "    val destPre = flightsArr\n",
    "    .repartition(numPartsDest, col(\"DEST_WBAN\"), col(\"UTC_ARR_DATE\"))     // <-- Hash partition explicite\n",
    "    .join(\n",
    "      weatherByKey.hint(\"shuffle_hash\"),\n",
    "      col(\"DEST_WBAN\") === weatherByKey(\"WBAN\") &&\n",
    "      col(\"UTC_ARR_DATE\")  === weatherByKey(\"DATE\"),\n",
    "      \"left\"\n",
    "    )\n",
    "    .drop(weatherByKey(\"WBAN\")).drop(weatherByKey(\"DATE\"))\n",
    "    \n",
    "    val destWithWdArr = destPre\n",
    "    .withColumn(\"Wd\", expr(\"transform(sequence(1, 3), i -> element_at(wmap, arrHour - i))\"))\n",
    "    .drop(\"wmap\")\n",
    "    \n",
    "    val wdCols = (0 until 3).map(i => col(\"Wd\").getItem(i).as(s\"Wd_h${i+1}\"))\n",
    "    \n",
    "    val baseCols: Seq[org.apache.spark.sql.Column] =\n",
    "      originDF.columns.map(col).toSeq\n",
    "    \n",
    "    val joinedDF = destWithWdArr\n",
    "      .select( (baseCols ++ wdCols): _* )\n",
    "      .drop(\"Wd\")\n",
    "      .persist()\n",
    "    \n",
    "    // ------------------------\n",
    "    // Action finale (déclenche l'exécution)\n",
    "    // ------------------------\n",
    "    println(s\"Rows after ORIGIN join: ${originDF.count()}, rows after DEST join: ${joinedDF.count()}\")\n",
    "}    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5df1516-55d5-46ea-a8ad-71099f11d84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- OP_CARRIER_AIRLINE_ID: integer (nullable = true)\n",
      " |-- DEST_AIRPORT_ID: integer (nullable = true)\n",
      " |-- ORIGIN_AIRPORT_ID: integer (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
      " |-- feature_arrival_time_period: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- feature_flight_week_of_year: integer (nullable = true)\n",
      " |-- feature_departure_time_period: string (nullable = true)\n",
      " |-- feature_departure_hour_rounded: long (nullable = true)\n",
      " |-- ARR_DELAY_NEW: double (nullable = true)\n",
      " |-- D1: integer (nullable = true)\n",
      " |-- D2_15: integer (nullable = true)\n",
      " |-- D2_30: integer (nullable = true)\n",
      " |-- D2_45: integer (nullable = true)\n",
      " |-- D2_60: integer (nullable = true)\n",
      " |-- D2_90: integer (nullable = true)\n",
      " |-- D3: integer (nullable = true)\n",
      " |-- D4: integer (nullable = true)\n",
      " |-- UTC_FL_DATE: date (nullable = true)\n",
      " |-- feature_utc_departure_hour_rounded: long (nullable = true)\n",
      " |-- feature_utc_arrival_hour_rounded: string (nullable = true)\n",
      " |-- feature_flight_unique_id: string (nullable = true)\n",
      " |-- ORIGIN_WBAN: string (nullable = true)\n",
      " |-- DEST_WBAN: string (nullable = true)\n",
      " |-- UTC_ARR_DATE: date (nullable = true)\n",
      " |-- UTC_CRS_DEP_TIME: string (nullable = true)\n",
      " |-- UTC_ARR_TIME: string (nullable = true)\n",
      " |-- WEATHER_DELAY: double (nullable = true)\n",
      " |-- NAS_DELAY: double (nullable = true)\n",
      " |-- FL_DATE: date (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n",
      " |-- CRS_ARR_TIME: string (nullable = true)\n",
      " |-- is_delayed: integer (nullable = false)\n",
      " |-- depHour: integer (nullable = false)\n",
      " |-- Wo_h1: struct (nullable = true)\n",
      " |    |-- hour: integer (nullable = false)\n",
      " |    |-- WBAN: string (nullable = true)\n",
      " |    |-- WDATE: date (nullable = true)\n",
      " |    |-- WTIME_HHMM: string (nullable = true)\n",
      " |    |-- feature_pressure_bucket: string (nullable = true)\n",
      " |    |-- weather_hazard_level: integer (nullable = true)\n",
      " |    |-- feature_weather_severity_index: double (nullable = true)\n",
      " |    |-- RelativeHumidity: double (nullable = true)\n",
      " |    |-- feature_visibility_category: string (nullable = true)\n",
      " |    |-- feature_flight_category_ordinal: integer (nullable = true)\n",
      " |    |-- feature_visibility_risk_score: double (nullable = true)\n",
      " |    |-- feature_requires_cat_ii: integer (nullable = true)\n",
      " |    |-- extracted_codes: string (nullable = true)\n",
      " |    |-- feature_operations_risk_level: integer (nullable = true)\n",
      " |    |-- feature_pressure_vis_combo_bin: string (nullable = true)\n",
      " |    |-- feature_most_critical_sky: string (nullable = true)\n",
      " |    |-- press_change_abs: double (nullable = true)\n",
      " |    |-- feature_is_very_low_visibility: integer (nullable = true)\n",
      " |-- Wo_h2: struct (nullable = true)\n",
      " |    |-- hour: integer (nullable = false)\n",
      " |    |-- WBAN: string (nullable = true)\n",
      " |    |-- WDATE: date (nullable = true)\n",
      " |    |-- WTIME_HHMM: string (nullable = true)\n",
      " |    |-- feature_pressure_bucket: string (nullable = true)\n",
      " |    |-- weather_hazard_level: integer (nullable = true)\n",
      " |    |-- feature_weather_severity_index: double (nullable = true)\n",
      " |    |-- RelativeHumidity: double (nullable = true)\n",
      " |    |-- feature_visibility_category: string (nullable = true)\n",
      " |    |-- feature_flight_category_ordinal: integer (nullable = true)\n",
      " |    |-- feature_visibility_risk_score: double (nullable = true)\n",
      " |    |-- feature_requires_cat_ii: integer (nullable = true)\n",
      " |    |-- extracted_codes: string (nullable = true)\n",
      " |    |-- feature_operations_risk_level: integer (nullable = true)\n",
      " |    |-- feature_pressure_vis_combo_bin: string (nullable = true)\n",
      " |    |-- feature_most_critical_sky: string (nullable = true)\n",
      " |    |-- press_change_abs: double (nullable = true)\n",
      " |    |-- feature_is_very_low_visibility: integer (nullable = true)\n",
      " |-- Wo_h3: struct (nullable = true)\n",
      " |    |-- hour: integer (nullable = false)\n",
      " |    |-- WBAN: string (nullable = true)\n",
      " |    |-- WDATE: date (nullable = true)\n",
      " |    |-- WTIME_HHMM: string (nullable = true)\n",
      " |    |-- feature_pressure_bucket: string (nullable = true)\n",
      " |    |-- weather_hazard_level: integer (nullable = true)\n",
      " |    |-- feature_weather_severity_index: double (nullable = true)\n",
      " |    |-- RelativeHumidity: double (nullable = true)\n",
      " |    |-- feature_visibility_category: string (nullable = true)\n",
      " |    |-- feature_flight_category_ordinal: integer (nullable = true)\n",
      " |    |-- feature_visibility_risk_score: double (nullable = true)\n",
      " |    |-- feature_requires_cat_ii: integer (nullable = true)\n",
      " |    |-- extracted_codes: string (nullable = true)\n",
      " |    |-- feature_operations_risk_level: integer (nullable = true)\n",
      " |    |-- feature_pressure_vis_combo_bin: string (nullable = true)\n",
      " |    |-- feature_most_critical_sky: string (nullable = true)\n",
      " |    |-- press_change_abs: double (nullable = true)\n",
      " |    |-- feature_is_very_low_visibility: integer (nullable = true)\n",
      " |-- Wd_h1: struct (nullable = true)\n",
      " |    |-- hour: integer (nullable = false)\n",
      " |    |-- WBAN: string (nullable = true)\n",
      " |    |-- WDATE: date (nullable = true)\n",
      " |    |-- WTIME_HHMM: string (nullable = true)\n",
      " |    |-- feature_pressure_bucket: string (nullable = true)\n",
      " |    |-- weather_hazard_level: integer (nullable = true)\n",
      " |    |-- feature_weather_severity_index: double (nullable = true)\n",
      " |    |-- RelativeHumidity: double (nullable = true)\n",
      " |    |-- feature_visibility_category: string (nullable = true)\n",
      " |    |-- feature_flight_category_ordinal: integer (nullable = true)\n",
      " |    |-- feature_visibility_risk_score: double (nullable = true)\n",
      " |    |-- feature_requires_cat_ii: integer (nullable = true)\n",
      " |    |-- extracted_codes: string (nullable = true)\n",
      " |    |-- feature_operations_risk_level: integer (nullable = true)\n",
      " |    |-- feature_pressure_vis_combo_bin: string (nullable = true)\n",
      " |    |-- feature_most_critical_sky: string (nullable = true)\n",
      " |    |-- press_change_abs: double (nullable = true)\n",
      " |    |-- feature_is_very_low_visibility: integer (nullable = true)\n",
      " |-- Wd_h2: struct (nullable = true)\n",
      " |    |-- hour: integer (nullable = false)\n",
      " |    |-- WBAN: string (nullable = true)\n",
      " |    |-- WDATE: date (nullable = true)\n",
      " |    |-- WTIME_HHMM: string (nullable = true)\n",
      " |    |-- feature_pressure_bucket: string (nullable = true)\n",
      " |    |-- weather_hazard_level: integer (nullable = true)\n",
      " |    |-- feature_weather_severity_index: double (nullable = true)\n",
      " |    |-- RelativeHumidity: double (nullable = true)\n",
      " |    |-- feature_visibility_category: string (nullable = true)\n",
      " |    |-- feature_flight_category_ordinal: integer (nullable = true)\n",
      " |    |-- feature_visibility_risk_score: double (nullable = true)\n",
      " |    |-- feature_requires_cat_ii: integer (nullable = true)\n",
      " |    |-- extracted_codes: string (nullable = true)\n",
      " |    |-- feature_operations_risk_level: integer (nullable = true)\n",
      " |    |-- feature_pressure_vis_combo_bin: string (nullable = true)\n",
      " |    |-- feature_most_critical_sky: string (nullable = true)\n",
      " |    |-- press_change_abs: double (nullable = true)\n",
      " |    |-- feature_is_very_low_visibility: integer (nullable = true)\n",
      " |-- Wd_h3: struct (nullable = true)\n",
      " |    |-- hour: integer (nullable = false)\n",
      " |    |-- WBAN: string (nullable = true)\n",
      " |    |-- WDATE: date (nullable = true)\n",
      " |    |-- WTIME_HHMM: string (nullable = true)\n",
      " |    |-- feature_pressure_bucket: string (nullable = true)\n",
      " |    |-- weather_hazard_level: integer (nullable = true)\n",
      " |    |-- feature_weather_severity_index: double (nullable = true)\n",
      " |    |-- RelativeHumidity: double (nullable = true)\n",
      " |    |-- feature_visibility_category: string (nullable = true)\n",
      " |    |-- feature_flight_category_ordinal: integer (nullable = true)\n",
      " |    |-- feature_visibility_risk_score: double (nullable = true)\n",
      " |    |-- feature_requires_cat_ii: integer (nullable = true)\n",
      " |    |-- extracted_codes: string (nullable = true)\n",
      " |    |-- feature_operations_risk_level: integer (nullable = true)\n",
      " |    |-- feature_pressure_vis_combo_bin: string (nullable = true)\n",
      " |    |-- feature_most_critical_sky: string (nullable = true)\n",
      " |    |-- press_change_abs: double (nullable = true)\n",
      " |    |-- feature_is_very_low_visibility: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinedDF.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23233df8-5a2b-4f57-9b30-8477ce74cf66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apache_toree_scala - Scala",
   "language": "scala",
   "name": "apache_toree_scala_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
