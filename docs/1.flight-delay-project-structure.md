# Structure de Projet Scala SBT - Flight Delay Prediction

## Structure des répertoires

```
flight-delay-prediction/
├── build.sbt
├── project/
│   ├── build.properties
│   └── plugins.sbt
├── src/
│   ├── main/
│   │   ├── scala/
│   │   │   └── com/flightdelay/
│   │   │       ├── config/
│   │   │       │   ├── AppConfig.scala
│   │   │       │   └── SparkConfig.scala
│   │   │       ├── data/
│   │   │       │   ├── loaders/
│   │   │       │   │   ├── FlightDataLoader.scala
│   │   │       │   │   ├── WeatherDataLoader.scala
│   │   │       │   │   └── DataLoader.scala
│   │   │       │   ├── preprocessing/
│   │   │       │   │   ├── FlightDataPreprocessor.scala
│   │   │       │   │   ├── WeatherDataPreprocessor.scala
│   │   │       │   │   └── DataCleaner.scala
│   │   │       │   ├── joiners/
│   │   │       │   │   ├── FlightWeatherJoiner.scala
│   │   │       │   │   └── TemporalJoiner.scala
│   │   │       │   └── model/
│   │   │       │       ├── Flight.scala
│   │   │       │       ├── WeatherObservation.scala
│   │   │       │       └── FlightDelayRecord.scala
│   │   │       ├── features/
│   │   │       │   ├── FeatureExtractor.scala
│   │   │       │   ├── WeatherFeatures.scala
│   │   │       │   ├── FlightFeatures.scala
│   │   │       │   └── TemporalFeatures.scala
│   │   │       ├── ml/
│   │   │       │   ├── models/
│   │   │       │   │   ├── RandomForestModel.scala
│   │   │       │   │   ├── DecisionTreeModel.scala
│   │   │       │   │   ├── LogisticRegressionModel.scala
│   │   │       │   │   └── SVMModel.scala
│   │   │       │   ├── training/
│   │   │       │   │   ├── ModelTrainer.scala
│   │   │       │   │   ├── CrossValidator.scala
│   │   │       │   │   └── HyperParameterTuner.scala
│   │   │       │   ├── evaluation/
│   │   │       │   │   ├── ModelEvaluator.scala
│   │   │       │   │   ├── MetricsCalculator.scala
│   │   │       │   │   └── PerformanceReporter.scala
│   │   │       │   └── pipeline/
│   │   │       │       ├── MLPipeline.scala
│   │   │       │       └── PipelineBuilder.scala
│   │   │       ├── utils/
│   │   │       │   ├── SparkSession.scala
│   │   │       │   ├── DateTimeUtils.scala
│   │   │       │   ├── FileUtils.scala
│   │   │       │   └── LoggingUtils.scala
│   │   │       └── app/
│   │   │           ├── FlightDelayPredictionApp.scala
│   │   │           ├── DataPreparationApp.scala
│   │   │           ├── ModelTrainingApp.scala
│   │   │           └── ModelEvaluationApp.scala
│   │   └── resources/
│   │       ├── application.conf
│   │       ├── log4j.properties
│   │       └── reference.conf
│   └── test/
│       ├── scala/
│       │   └── com/flightdelay/
│       │       ├── data/
│       │       │   ├── FlightDataLoaderTest.scala
│       │       │   ├── WeatherDataLoaderTest.scala
│       │       │   └── JoinerTest.scala
│       │       ├── features/
│       │       │   ├── FeatureExtractorTest.scala
│       │       │   └── WeatherFeaturesTest.scala
│       │       ├── ml/
│       │       │   ├── RandomForestModelTest.scala
│       │       │   ├── ModelEvaluatorTest.scala
│       │       │   └── MLPipelineTest.scala
│       │       └── utils/
│       │           └── DateTimeUtilsTest.scala
│       └── resources/
│           ├── test-data/
│           │   ├── sample_flights.csv
│           │   └── sample_weather.csv
│           └── test.conf
├── data/
│   ├── raw/
│   │   ├── flights/
│   │   └── weather/
│   ├── processed/
│   │   ├── cleaned/
│   │   ├── features/
│   │   └── joined/
│   └── models/
│       ├── trained/
│       └── evaluation/
├── scripts/
│   ├── setup.sh
│   ├── run-local.sh
│   ├── run-cluster.sh
│   ├── data-download.sh
│   └── submit-spark.sh
├── docs/
│   ├── README.md
│   ├── DATA_SCHEMA.md
│   ├── MODEL_EVALUATION.md
│   └── DEPLOYMENT.md
├── notebooks/
│   ├── data_exploration.ipynb
│   ├── feature_analysis.ipynb
│   └── model_comparison.ipynb
└── docker/
    ├── Dockerfile
    ├── docker-compose.yml
    └── spark-cluster/

```

## Configuration des fichiers principaux

### build.sbt
```scala
ThisBuild / version := "0.1.0-SNAPSHOT"
ThisBuild / scalaVersion := "2.12.17"

val sparkVersion = "3.4.1"
val configVersion = "1.4.2"
val scalatestVersion = "3.2.16"
val logbackVersion = "1.4.8"

lazy val root = (project in file("."))
  .settings(
    name := "flight-delay-prediction",
    libraryDependencies ++= Seq(
      // Spark
      "org.apache.spark" %% "spark-core" % sparkVersion % "provided",
      "org.apache.spark" %% "spark-sql" % sparkVersion % "provided",
      "org.apache.spark" %% "spark-mllib" % sparkVersion % "provided",
      
      // Configuration
      "com.typesafe" % "config" % configVersion,
      
      // Logging
      "ch.qos.logback" % "logback-classic" % logbackVersion,
      
      // Testing
      "org.scalatest" %% "scalatest" % scalatestVersion % Test,
      "org.apache.spark" %% "spark-core" % sparkVersion % Test classifier "tests",
      "org.apache.spark" %% "spark-sql" % sparkVersion % Test classifier "tests",
      "org.apache.spark" %% "spark-catalyst" % sparkVersion % Test classifier "tests",
      
      // Date/Time
      "joda-time" % "joda-time" % "2.12.5",
      "org.joda" % "joda-convert" % "2.2.1"
    ),
    
    // Assembly settings pour créer un JAR exécutable
    assembly / assemblyMergeStrategy := {
      case PathList("META-INF", xs @ _*) => MergeStrategy.discard
      case "application.conf" => MergeStrategy.concat
      case "reference.conf" => MergeStrategy.concat
      case _ => MergeStrategy.first
    },
    
    // Options de compilation
    scalacOptions ++= Seq(
      "-deprecation",
      "-feature",
      "-unchecked",
      "-Xlint",
      "-encoding", "UTF-8"
    ),
    
    // Paramètres JVM pour tests
    Test / javaOptions ++= Seq(
      "-Xmx2g"
    )
  )
```

### project/plugins.sbt
```scala
addSbtPlugin("com.eed3si9n" % "sbt-assembly" % "2.1.1")
addSbtPlugin("org.scalameta" % "sbt-scalafmt" % "2.5.0")
addSbtPlugin("org.scoverage" % "sbt-scoverage" % "2.0.8")
```

### project/build.properties
```
sbt.version=1.9.2
```

## Structure des classes principales

### 1. Modèles de données (src/main/scala/com/flightdelay/data/model/)

#### Flight.scala
```scala
package com.flightdelay.data.model

import java.time.LocalDateTime

case class Flight(
  originAirport: String,
  destinationAirport: String,
  scheduledDepartureTime: LocalDateTime,
  actualDepartureTime: Option[LocalDateTime],
  scheduledArrivalTime: LocalDateTime,
  actualArrivalTime: Option[LocalDateTime],
  carrier: String,
  flightNumber: String,
  tailNumber: Option[String],
  cancelled: Boolean,
  diverted: Boolean
) {
  def arrivalDelay: Option[Int] = {
    for {
      actual <- actualArrivalTime
      scheduled = scheduledArrivalTime
    } yield java.time.Duration.between(scheduled, actual).toMinutes.toInt
  }
  
  def isDelayed(threshold: Int = 15): Boolean = {
    arrivalDelay.exists(_ >= threshold)
  }
}
```

#### WeatherObservation.scala
```scala
package com.flightdelay.data.model

import java.time.LocalDateTime

case class WeatherObservation(
  airport: String,
  observationTime: LocalDateTime,
  temperature: Option[Double],
  humidity: Option[Double],
  windDirection: Option[Int],
  windSpeed: Option[Double],
  pressure: Option[Double],
  skyCondition: Option[String],
  visibility: Option[Double],
  weatherPhenomena: Option[String]
)
```

### 2. Configuration (src/main/scala/com/flightdelay/config/)

#### AppConfig.scala
```scala
package com.flightdelay.config

import com.typesafe.config.{Config, ConfigFactory}

object AppConfig {
  private val config: Config = ConfigFactory.load()
  
  object Data {
    val flightDataPath: String = config.getString("data.flight.path")
    val weatherDataPath: String = config.getString("data.weather.path")
    val outputPath: String = config.getString("data.output.path")
  }
  
  object Model {
    val delayThreshold: Int = config.getInt("model.delay.threshold")
    val trainingRatio: Double = config.getDouble("model.training.ratio")
    val randomSeed: Long = config.getLong("model.random.seed")
  }
  
  object Spark {
    val appName: String = config.getString("spark.app.name")
    val master: String = config.getString("spark.master")
  }
}
```

### 3. Applications principales (src/main/scala/com/flightdelay/app/)

#### FlightDelayPredictionApp.scala

```scala
package com.flightdelay.app

import com.flightdelay.config.AppConfig
import com.flightdelay.data.loaders.FlightDataLoader
import com.flightdelay.data.joiners.FlightWeatherJoiner
import com.flightdelay.features.FeatureExtractor
import com.flightdelay.ml.pipeline.MLPipeline
import com.flightdelay.utils.SparkSession
import org.apache.spark.sql.SparkSession

object FlightDelayPredictionApp {

  def main(args: Array[String]): Unit = {
    implicit val spark: SparkSession = SparkSession.getOrCreateSession()

    try {
      println("Starting Flight Delay Prediction Pipeline...")

      // 1. Data Loading
      val flightData = FlightDataLoader.load(AppConfig.Data.flightDataPath)
      val weatherData = WeatherDataLoader.load(AppConfig.Data.weatherDataPath)

      // 2. Data Joining
      val joinedData = FlightWeatherJoiner.join(flightData, weatherData)

      // 3. Feature Extraction
      val featuredData = FeatureExtractor.extract(joinedData)

      // 4. ML Pipeline
      val pipeline = new MLPipeline()
      val model = pipeline.train(featuredData)

      // 5. Model Evaluation
      val results = pipeline.evaluate(model, featuredData)

      println("Pipeline completed successfully!")
      results.show()

    } catch {
      case ex: Exception =>
        println(s"Error in pipeline: ${ex.getMessage}")
        ex.printStackTrace()
    } finally {
      spark.stop()
    }
  }
}
```

## Ressources de configuration

### src/main/resources/application.conf
```hocon
data {
  flight {
    path = "data/raw/flights/"
  }
  weather {
    path = "data/raw/weather/"
  }
  output {
    path = "data/processed/"
  }
}

model {
  delay {
    threshold = 15  // minutes
  }
  training {
    ratio = 0.8
  }
  random {
    seed = 42
  }
}

spark {
  app {
    name = "FlightDelayPrediction"
  }
  master = "local[*]"  // Override for cluster deployment
}
```

## Scripts d'exécution

### scripts/run-local.sh
```bash
#!/bin/bash

echo "Running Flight Delay Prediction locally..."

# Set Spark configuration for local execution
export SPARK_CONF="--conf spark.sql.adaptive.enabled=true --conf spark.sql.adaptive.coalescePartitions.enabled=true"

sbt "runMain com.flightdelay.app.FlightDelayPredictionApp"
```

### scripts/run-cluster.sh
```bash
#!/bin/bash

echo "Submitting to Spark cluster..."

# Build the application JAR
sbt assembly

# Submit to cluster
spark-submit \
  --class com.flightdelay.app.FlightDelayPredictionApp \
  --master yarn \
  --deploy-mode cluster \
  --conf spark.sql.adaptive.enabled=true \
  --conf spark.sql.adaptive.coalescePartitions.enabled=true \
  --executor-memory 4g \
  --driver-memory 2g \
  --num-executors 10 \
  target/scala-2.12/flight-delay-prediction-assembly-0.1.0-SNAPSHOT.jar
```

## Architecture et workflow

Le projet suit cette architecture modulaire :

1. **Phase de préparation des données** : Chargement, nettoyage et préprocessing
2. **Phase de jointure** : Jointures complexes temporelles entre données de vol et météo
3. **Phase d'extraction de features** : Création des features pour le machine learning
4. **Phase d'entraînement** : Entraînement des modèles (Random Forest prioritaire)
5. **Phase d'évaluation** : Évaluation des performances et métriques

Cette structure permettra d'implémenter efficacement le projet de prédiction de retards de vol avec une scalabilité pour traitement distribué sur cluster.
