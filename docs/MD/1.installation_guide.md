# Installation

## Prérequis

Assurez-vous d'avoir les versions suivantes installées sur votre système :

- **Scala** : 2.12.18
- **Java** : 17.0.13
- **Spark** : 3.5.5

## Configuration de l'Environnement

### 1. Installation

Télécharger le zip du projet ou cloner le en utilisant Git. 

### 2. Préparation des Scripts

Si vous êtes sous Linux ou Mac, ouvrez un terminal et naviguez vers le répertoire racine du projet. 
Rendez les scripts exécutables :

```bash
sudo chmod +x ./docker/setup.sh
sudo chmod +x ./start.sh
sudo chmod +x ./stop.sh
sudo chmod +x ./submit.sh
```

### 2. Construction du Cluster Spark Local avec Docker

Ouvrir un terminal puis exécuter les commandes suivantes :
```bash
cd docker
./setup.sh
```
La commande compilera et téléchargera les images docker nécessaires pour construire le cluster en local sur votre installation docker.
Le script après avoir créé le cluster docker, le démarre automatiquement.

### 3. Gestion du Cluster Local

**Pour Démarrer/Redémarrer le cluster :**
```bash
./start.sh
```

**Pour Arrêter le cluster :**
```bash
./stop.sh
```

**Pour recompiler et soumettre le projet sur le cluster local :**
```bash
./submit.sh
```

### 4. Gestion du Cluster Lamsade

Avant tout, copiez votre fichier **id_ed25519_mchettih.key** à la racine du répertoire du projet.
Cette clé est nécessaire pour se connecter au Cluster de lamsade.

Pour se connecter au cluster de Lamsade, ouvrir un tunnel SSH en exécutant la commande suvante:
```bash
ssh -p 5022 -i id_ed25519_mchettih.key mchettih@ssh.lamsade.dauphine.fr
```

#### Étape 1 : Préparation des Fichiers
Avant d'exécuter le programme sur l'application Spark sur le cluster il est nécessaire d'installer le dataset sur le cluster.

Pour cela télécharger le dataset (FLIGHT-3Y.zip) sur votre poste depuis l'URL https://www.dropbox.com/sh/iasq7frk6f58ptq/AAAzSmk6cusSNfqYNYsnLGIXa.
Puis uploader le fichier sur le cluster en exécutant cette commande.

```bash
# Transfert des données et du JAR sur le serveur
scp -P 5022 -i id_ed25519_mchettih.key FLIGHT-3Y.zip mchettih@ssh.lamsade.dauphine.fr:~/workspace
```
Attention: le fichier est envoyé dans le répertoire **workspace** à la racine du répertoire Home du Cluster.

Une fois le transfert terminé, se connecter au cluster et ouvrir une session SSH avec:
```bash
ssh -p 5022 -i id_ed25519_mchettih.key mchettih@ssh.lamsade.dauphine.fr
```

Puis charger les fichiers du dataset sous HDFS. Attention à bien mettre à jour les chemins en fonction de votre environnement:
```bash
# Décompression des données
cp FLIGHT-3Y.zip ./data/
cd ./data
unzip FLIGHT-3Y.zip
rm FLIGHT-3Y.zip

# Création des répertoires HDFS
hdfs dfs -mkdir -p /students/p6emiasd2025/mchettih/data/FLIGHT-3Y
hdfs dfs -mkdir -p /students/p6emiasd2025/mchettih/data/FLIGHT-3Y/Flights
hdfs dfs -mkdir -p /students/p6emiasd2025/mchettih/data/FLIGHT-3Y/Weather

# Transfert des données vers HDFS
hdfs dfs -put data/FLIGHT-3Y/wban_airport_timezone.csv /students/p6emiasd2025/mchettih/data/FLIGHT-3Y
hdfs dfs -put data/FLIGHT-3Y/Flights/* /students/p6emiasd2025/mchettih/data/FLIGHT-3Y/Flights
hdfs dfs -put data/FLIGHT-3Y/Weather/* /students/p6emiasd2025/mchettih/data/FLIGHT-3Y/Weather
```

#### Étape 2 : Compilation, Transfert & Exécution

Pour exécuter l'application Spark, il est nécessaire de la compiler sur votre poste de développement. 
Puis de l'uploader dans le répertoire workspace du Cluster de Lamsade. Pour cela,exécutez les commandes suivantes 
depuis votre poste de développement :

```bash
# Compilation du projet
sbt package

# Transfert des données et du JAR sur le serveur
scp -P 5022 -i id_ed25519_mchettih.key ./work/apps/Emiasd-Flight-Data-Analysis.jar mchettih@ssh.lamsade.dauphine.fr:~/workspace
```

Connectez vous au cluster.
```bash
ssh -p 5022 -i id_ed25519_mchettih.key mchettih@ssh.lamsade.dauphine.fr
```

Puis, depuis la session ssh dans le cluster, exécuter les commandes suivantes :

```bash
cd /opt/cephfs/users/students/p6emiasd2025/mchettih/workspace

spark-submit \
  --deploy-mode client \
  --class com.flightdelay.app.FlightDelayPredictionApp \
  --executor-cores 4 \
  --executor-memory 2G \
  --num-executors 1 \
  Emiasd-Flight-Data-Analysis.jar \
  lamsade
```

## Services Additionnels

### Jupyter Lab

Une fois le cluster local démarré, Jupyter Lab est accessible à l'adresse :
**http://localhost:8888**

### Données

Les données sont stockées dans le répertoire `./work/data/FLIGHT-3Y` et sont accessibles depuis :
- Les notebooks Jupyter
- Les jobs Spark du cluster local

## Vérification de l'Installation

Pour vérifier que l'installation s'est bien déroulée :

1. **Cluster local** : Vérifiez que Spark UI est accessible sur http://localhost:4040
2. **Jupyter** : Accédez à http://localhost:8888 et vérifiez la disponibilité des données
3. **Cluster Lamsade** : Vérifiez les logs de spark-submit pour s'assurer de l'exécution correcte