# Installation

## Prérequis

Assurez-vous d'avoir les versions suivantes installées sur votre système :

- **Scala** : 2.12.18
- **Java** : 17.0.13
- **Spark** : 3.5.5

## Configuration de l'Environnement

### 1. Installation

Télécharger le zip du projet ou cloner le en utilisant Git. 

### 2. Préparation des Scripts

Si vous êtes sous Linux ou Mac, ouvrez un terminal et naviguez vers le répertoire racine du projet. 
Rendez les scripts exécutables :

```bash
sudo chmod +x ./docker/setup.sh
sudo chmod +x ./start-local-cluster.sh
sudo chmod +x ./stop-local-cluster.sh
sudo chmod +x ./run-on-docker.sh
```

### 2. Construction du Cluster Spark Local avec Docker

Ouvrir un terminal puis exécuter les commandes suivantes :
```bash
cd docker
./setup.sh
```
La commande compilera et téléchargera les images docker nécessaires pour construire le cluster en local sur votre installation docker.
Le script après avoir créé le cluster docker, le démarre automatiquement.

### 3. Gestion du Cluster Local

**Pour Démarrer/Redémarrer le cluster :**
```bash
./start-local-cluster.sh
```

**Pour Arrêter le cluster :**
```bash
./stop-local-cluster.sh
```

**Pour recompiler et soumettre le projet sur le cluster local :**
```bash
./run-on-docker.sh
```

### 4. Gestion du Cluster Lamsade

#### Étape 1 : Préparation des Fichiers

Avant tout, copiez votre fichier **id_ed25519_mchettih.key** à la racine du répertoire du projet.

#### Étape 2 : Compilation et Transfert

Exécutez les commandes suivantes depuis votre poste de développement :

```bash
# Compilation du projet
sbt package

# Transfert des données et du JAR sur le serveur
scp -P 5022 -i id_ed25519_mchettih.key ./work/data/FLIGHT-3Y.zip mchettih@ssh.lamsade.dauphine.fr:~/workspace
scp -P 5022 -i id_ed25519_mchettih.key ./work/apps/Emiasd-Flight-Data-Analysis.jar mchettih@ssh.lamsade.dauphine.fr:~/workspace
```

#### Étape 3 : Configuration sur le Serveur

Connectez-vous au serveur :

```bash
ssh -p 5022 -i id_ed25519_mchettih.key mchettih@ssh.lamsade.dauphine.fr
```

Une fois connecté, exécutez les commandes suivantes :

```bash
# Décompression des données
cp FLIGHT-3Y.zip ./data/
cd ./data
unzip FLIGHT-3Y.zip
rm FLIGHT-3Y.zip

# Création des répertoires HDFS
hdfs dfs -mkdir -p /students/p6emiasd2025/mchettih/data/FLIGHT-3Y
hdfs dfs -mkdir -p /students/p6emiasd2025/mchettih/data/FLIGHT-3Y/Flights
hdfs dfs -mkdir -p /students/p6emiasd2025/mchettih/data/FLIGHT-3Y/Weather

# Transfert des données vers HDFS
hdfs dfs -put data/FLIGHT-3Y/wban_airport_timezone.csv /students/p6emiasd2025/mchettih/data/FLIGHT-3Y
hdfs dfs -put data/FLIGHT-3Y/Flights/* /students/p6emiasd2025/mchettih/data/FLIGHT-3Y/Flights
hdfs dfs -put data/FLIGHT-3Y/Weather/* /students/p6emiasd2025/mchettih/data/FLIGHT-3Y/Weather
```

#### Étape 4 : Exécution de l'Application

Depuis le répertoire de travail sur le cluster :

```bash
cd /opt/cephfs/users/students/p6emiasd2025/mchettih/workspace

spark-submit \
  --deploy-mode client \
  --class com.flightdelay.app.FlightDelayPredictionApp \
  --executor-cores 4 \
  --executor-memory 2G \
  --num-executors 1 \
  Emiasd-Flight-Data-Analysis.jar \
  lamsade
```

## Services Additionnels

### Jupyter Lab

Une fois le cluster local démarré, Jupyter Lab est accessible à l'adresse :
**http://localhost:8888**

### Données

Les données sont stockées dans le répertoire `./work/data/FLIGHT-3Y` et sont accessibles depuis :
- Les notebooks Jupyter
- Les jobs Spark du cluster local

## Vérification de l'Installation

Pour vérifier que l'installation s'est bien déroulée :

1. **Cluster local** : Vérifiez que Spark UI est accessible sur http://localhost:4040
2. **Jupyter** : Accédez à http://localhost:8888 et vérifiez la disponibilité des données
3. **Cluster Lamsade** : Vérifiez les logs de spark-submit pour s'assurer de l'exécution correcte